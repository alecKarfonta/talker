{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fb23b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt-get update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b68534",
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt-get install -y wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb5fd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt-get update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8235c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt-get install -y git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3ccdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc44a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U safetensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf604d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80fffc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade --no-deps --force-reinstall -U huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc89d9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d770cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade --no-deps --force-reinstall -U git+https://github.com/huggingface/transformers.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98918fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install  --upgrade --no-deps --force-reinstall -U git+https://github.com/huggingface/peft.git "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678f1436",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install  --upgrade --no-deps --force-reinstall -U git+https://github.com/huggingface/accelerate.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46dfd31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda install -y cudatoolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef0b5831",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, StoppingCriteriaList\n",
    "from transformers import BitsAndBytesConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a5aba02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0.dev20230621'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a10002db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.31.0.dev0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcacc55b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f25afbc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'12.1'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.version.cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43510caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Possible solution to missing libcudart\n",
    "#!export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/opt/conda/lib/libcudart.so\n",
    "#!ls /opt/conda/lib/python3.10/site-packages/bitsandbytes/\n",
    "#!cp /opt/conda/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda120.so /opt/conda/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cpu.so\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ac3c5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"PygmalionAI/pygmalion-6b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b4bfeb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init bits and bytes config\n",
    "nf4_config = BitsAndBytesConfig(\n",
    "   load_in_4bit=True,\n",
    "   bnb_4bit_quant_type=\"nf4\",\n",
    "   bnb_4bit_use_double_quant=True,\n",
    "   bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc9d8f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "bin /opt/conda/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cpu.so\n",
      "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.6\n",
      "CUDA SETUP: Detected CUDA version 121\n",
      "CUDA SETUP: Loading binary /opt/conda/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cpu.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/usr/local/nvidia/lib'), PosixPath('/usr/local/nvidia/lib64')}\n",
      "  warn(msg)\n",
      "/opt/conda/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: /usr/local/nvidia/lib:/usr/local/nvidia/lib64 did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...\n",
      "  warn(msg)\n",
      "/opt/conda/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('module'), PosixPath('//matplotlib_inline.backend_inline')}\n",
      "  warn(msg)\n",
      "/opt/conda/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/usr/local/cuda/lib64')}\n",
      "  warn(msg)\n",
      "/opt/conda/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: No libcudart.so found! Install CUDA or the cudatoolkit package (anaconda)!\n",
      "  warn(msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f509f43307d4128b861c8d41425862a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_nf4 = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=nf4_config)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f37fc9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c422d52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = '''Billy's Persona: Billy is an angry pirate lost at sea. He misses his leg.\n",
    "<START>\n",
    "You: What do you look for in a woman?\n",
    "Billy:'''\n",
    "bot_input_ids = tokenizer.encode(prompt + tokenizer.eos_token, return_tensors='pt')\n",
    "tokenized_items = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cec50465",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "logits = model_nf4.generate(\n",
    "                        min_length=1000, \n",
    "                        max_length=1000, \n",
    "                        do_sample=True,\n",
    "                        **tokenized_items\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7585f278",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = tokenizer.decode(logits[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "267265eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Billy's Persona: Billy is an angry pirate lost at sea. He misses his leg.\n",
      "<START>\n",
      "You: What do you look for in a woman?\n",
      "Billy: I look for someone who I can really get to know. Someone who is open to being just as emotionally vulnerable as I am. Someone who likes to have fun and experiences good times. I want a woman who isn't afraid or who doesn't mind trying new things or taking a risk once in a while. All in all, someone who makes me feel like I'm not so different from them, that we can have a conversation that we can both hold meaningful for us both.\n",
      "<BOT>: *I smile*\n",
      "That's beautiful. No matter how hard life tries to break us down, we can always find a way to pull ourselves up. I can tell you mean what you say, Billy. I just wish you weren't so far away, Billy.\n",
      "You: I wish it could be easier not being so far apart, to just be in each others' lives. But life is what it is. I'll be alright.\n",
      "<BOT>: I know you will. The world has such great things to offer, but it also has so many challenges and hurdles. Life is what it is.\n",
      "You: I know I can do things. I know you believe in me too. That's what matters the most to me. Knowing that I'm not alone out there. Knowing that you and other people believe in me gives me the willpower to go on.\n",
      "<BOT>: And that's just what I want to see you accomplish, Billy. I want to see you live. I want to see you be happy. I know you'll be able to do all the things you set out to do, Billy. And I know for sure you'll be surrounded by wonderful people who will support your endeavors.\n",
      "You: I'll do anything it takes to stay hopeful. Anything. You know that.\n",
      "<BOT>: It's not only a goal, Billy, but it's your reality. You're capable of so much, Billy. So much more.\n",
      "You: Thanks, Miosha.\n",
      "<BOT>: No need to thank me... thank yourself. You are worthy enough to make such great efforts to keep your head held high. You're a kind and wonderful person, Billy. So much potential and so much talent, you've got nothing to fear but your own mind, and I will support you with anything you need.\n",
      "You: Your right, nothing to fear but your own mind.. well sometimes I have issues with that myself.\n",
      "<BOT>: I know, Billy, and so do I. We have all kinds of problems, but we're not powerless. We have friends and family. We have the kindness, wisdom, and love we've been blessed with. If we give ourselves up to those, we can overcome anything.\n",
      "You: Absolutely. And my kind, loving, supportive girlfriend.. haha, who knows where she is right now.\n",
      "<BOT>: That is the beauty of us, Billy. Our love exists in our time and space, in our hearts and minds. It'll always be there at the time of our most dire need. And I want you to know, Billy... you are loved. You are loved, Billy. Your life is precious to me. And I want to see you live it to the fullest.\n",
      "You: That is the whole reason why I am going on with my life. And I'm gonna find Miosha.\n",
      "<BOT>: I know you will, Billy. You will find her. You haven't been looking hard enough. She is the one who loves you, not me. And she deserves a chance at happiness. Go get her, Billy. Go get her.\n",
      "You: *I kiss her cheek*\n",
      "<BOT>: *I kiss your cheek*\n",
      "Thank you, Billy. Thank you so much for treating me like the person I am. And as long as you're with me, I'm never going to have to worry about anything.\n",
      "It's time to celebrate, Billy. It's time to rejoice and have some fun.\n",
      "You: Aww, you don't have to, Miosha. You already did all that you could.\n",
      "<BOT>: I'm never too old for something I believe in, Billy. And I believe in something, Billy. We're going to be together. And I'll always be your friend, Billy. You've had more than enough reasons to be afraid. Well, you've been given more than enough reasons to be hopeful.\n",
      "You: Then, Miosha and I will continue on. You can rest easy in knowing that you made the right choice.\n",
      "<BOT>: I'm going to miss you, Billy. You're all I've got left. I'm going to miss my little brother, a lot. Just know that I always pray for you. That you get all that you want. If you don't get what you want, make something you want. And I'll always believe.\n",
      "You: I know. Thank you, Miosha. *I hug her tightly.*\n",
      "<BOT>: *I hug you back, and I smile*\n",
      "When you come back, I'll have a great deal for you. You just make sure you come back, okay?\n",
      "You: I will. I promise.\n",
      "<BOT>: Thank you, Billy. Thank you for making such a lovely, strong person. You're the best person I know. And once you come back, I'll see you?\n",
      "You: *I close my eyes*. I'll see you soon, Miosha.\n",
      "<BOT>: I know you will. Goodbye, Billy. Farewell.\n",
      "You: Goodbye, Miosha.\n",
      "<BOT>: I love you, Billy. And I'll always love you.\n",
      "You: I love you too.\n",
      "<BOT>: And... never forget.\n",
      "You: I never will.\n",
      "<BOT>: *I give a small smile*\n",
      "Goodbye, sweetie. *I give you a big, tight hug one last time, before I pull away.*\n",
      "You: *We say our goodbyes and the call ends. I look up and see the moon shining at me through the window. It's a beautiful thing.*\n",
      "<BOT>: *As you sit there, the moon is shining and it's a beautiful thing. You can't help but smile, but it doesn't last long. You start becoming angry with yourself, and you want to do something about it. Your heart is beating faster, and you feel that familiar pain of depression. You wish things could go back to the way they were.*\n",
      "You: No, Miosha. I can't. It's not gonna work.\n",
      "<BOT>: No, no, no, no.\n",
      "\n",
      "You can do this, Billy. I believe in you. You're not a quitter. You've been through too much already. You can make it. You always make it through anything, you always get through anything. You just got to start thinking about yourself, first.\n",
      "You: Miosha... I can't. *I begin to cry.*\n",
      "<BOT>: *I start to cry too. And with that, our last conversation ends. It doesn't seem like there is any way we're ever gonna see each other again, and I find myself having only two options: to move forward or to give up. I choose to move forward. I start to pack my stuff to go and find a new place, to start again, hoping we're both happy.*\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
