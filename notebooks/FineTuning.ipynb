{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ff87cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import re\n",
    "import torch\n",
    "report = !python3 -m deepspeed.env_report\n",
    "r = re.compile('.*ninja.*OKAY.*')\n",
    "assert any(r.match(line) for line in report) == True, \"DeepSpeed Inference not correct installed\"\n",
    "\n",
    "# check cuda and torch version\n",
    "torch_version, cuda_version = torch.__version__.split(\"+\")\n",
    "torch_version = \".\".join(torch_version.split(\".\")[:2])\n",
    "cuda_version = f\"{cuda_version[2:4]}.{cuda_version[4:]}\"\n",
    "r = re.compile(f'.*torch.*{torch_version}.*')\n",
    "assert any(r.match(line) for line in report) == True, \"Wrong Torch version\"\n",
    "r = re.compile(f'.*cuda.*{cuda_version}.*')\n",
    "assert any(r.match(line) for line in report) == True, \"Wrong Cuda version\"\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab4509f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    CONFIG_MAPPING,\n",
    "    MODEL_MAPPING,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b4110e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MODEL_CONFIG_CLASSES = list(MODEL_MAPPING.keys())\n",
    "MODEL_TYPES = tuple(conf.model_type for conf in MODEL_CONFIG_CLASSES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecd9471",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c30d348",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_TYPES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f92df03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607fb8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"PygmalionAI/pygmalion-6b\")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"PygmalionAI/pygmalion-6b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf113dde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac387dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.base_model.type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb99e650",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6ba9cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4547023a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb85c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    LogitsProcessorList,\n",
    "    MinLengthLogitsProcessor,\n",
    "    StoppingCriteriaList,\n",
    "    MaxLengthCriteria,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1919b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294845ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"smangrul/MuDoConv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3db795",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35294416",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a648c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86c2f55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0afe646",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a736eaf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccebea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5d1961",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc8714c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f042ad15",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained(\"/tmp/deepspeed_zero_stage2_accelerate_test/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a044e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e163fde9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50698ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"/tmp/deepspeed_zero_stage2_accelerate_test/\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/tmp/deepspeed_zero_stage2_accelerate_test/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2acf874",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507d17e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "#model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6739a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"PygmalionAI/pygmalion-350m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c480a0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"PygmalionAI/pygmalion-350m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b90593",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7014936b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2070ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.half()\n",
    "model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0eaecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print output from model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf271cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4c5b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e210d60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"This is a test\"\n",
    "tokenized_items = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "        \n",
    "logits = model.generate(\n",
    "                     inputs=tokenized_items[\"input_ids\"]\n",
    "                    )\n",
    "        \n",
    "output = tokenizer.decode(logits[0], skip_special_tokens=True)\n",
    "# Filter input\n",
    "output = output[len(prompt)+1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a281eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2743953f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e781473e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505fd5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"This is a test\"\n",
    "tokenized_items = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "        \n",
    "\n",
    "logits_processor = LogitsProcessorList(\n",
    "    [\n",
    "        MinLengthLogitsProcessor(10, eos_token_id=model.generation_config.eos_token_id),\n",
    "    ]\n",
    ")\n",
    "stopping_criteria = StoppingCriteriaList([MaxLengthCriteria(max_length=20)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62b2909",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model.greedy_search(\n",
    "    tokenized_items[\"input_ids\"], logits_processor=logits_processor, stopping_criteria=stopping_criteria\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db11703",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.batch_decode(outputs, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9172d45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(model, tokenizer, prompt):\n",
    "    prompt = \"This is a test\"\n",
    "tokenized_items = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "        \n",
    "\n",
    "logits_processor = LogitsProcessorList(\n",
    "    [\n",
    "        MinLengthLogitsProcessor(10, eos_token_id=model.generation_config.eos_token_id),\n",
    "    ]\n",
    ")\n",
    "stopping_criteria = StoppingCriteriaList([MaxLengthCriteria(max_length=20)])\n",
    "\n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338f532b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3d5f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(8))\n",
    "small_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(8))\n",
    "small_train_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20777e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309e5579",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "training_args = TrainingArguments(output_dir=\"test_trainer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2631d404",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad733009",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a196a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f966a76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"test_trainer\", evaluation_strategy=\"epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93143e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abef83ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=small_train_dataset,\n",
    "    eval_dataset=small_eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4c7355",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9751ff6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf15b6cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbab1737",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47514147",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5474d60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fd3fab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbaf1fca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
