{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb1e356",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ls /opt/conda/lib/libcud*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff342c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/opt/conda/lib/libcudart.so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abaa46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /opt/conda/lib/python3.10/site-packages/bitsandbytes/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4059e179",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp /opt/conda/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda118.so /opt/conda/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cpu.so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a93ef07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06ddae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto reload imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a16cc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -r requirements_1.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e13027",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d10b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['LD_LIBRARY_PATH'] = '/opt/conda/lib/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0ac375",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip uninstall -y torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8650f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip uninstall -y torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a0dd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130cb7cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "55bf6fee",
   "metadata": {},
   "source": [
    "Version Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b374c6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade google-api-python-client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8d8b209",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import IPython\n",
    "import torch\n",
    "import torchaudio\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c1b995b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.__version__ = '2.0.1+cu118'\n"
     ]
    }
   ],
   "source": [
    "print (f\"{torch.__version__ = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36798bc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.2+cu118'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchaudio.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c30734e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformers.__version__ = '4.31.0.dev0'\n"
     ]
    }
   ],
   "source": [
    "print (f\"{transformers.__version__ = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d284a77d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.cuda.is_available() = True\n"
     ]
    }
   ],
   "source": [
    "print (f\"{torch.cuda.is_available() = }\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54a580e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.version.cuda = '11.8'\n"
     ]
    }
   ],
   "source": [
    "print (f\"{torch.version.cuda = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5f41b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.cuda.get_device_name(0) = 'NVIDIA GeForce RTX 3090 Ti'\n"
     ]
    }
   ],
   "source": [
    "print (f\"{torch.cuda.get_device_name(0) = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17877f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bb14b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75b34ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install soundfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89ede365",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07acd2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install evaluate jiwer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22be18cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from copy import copy\n",
    "from typing import List\n",
    "import IPython\n",
    "import transformers\n",
    "from datetime import datetime\n",
    "from numpy.random import random\n",
    "from color import Color\n",
    "\n",
    "#import torchaudio\n",
    "#import IPython.display as ipd\n",
    "\n",
    "from sentiment import Sentiment, SentimentScore\n",
    "from conversation import Conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f80fa0d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "bin /opt/conda/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cpu.so\n",
      "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...\n",
      "ERROR: /opt/conda/bin/python: undefined symbol: cudaRuntimeGetVersion\n",
      "CUDA SETUP: libcudart.so path is None\n",
      "CUDA SETUP: Is seems that your cuda installation is not in your path. See https://github.com/TimDettmers/bitsandbytes/issues/85 for more information.\n",
      "CUDA SETUP: CUDA version lower than 11 are currently not supported for LLM.int8(). You will be only to use 8-bit optimizers and quantization routines!!\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.6\n",
      "CUDA SETUP: Detected CUDA version 00\n",
      "CUDA SETUP: Loading binary /opt/conda/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cpu.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/usr/local/nvidia/lib'), PosixPath('/usr/local/nvidia/lib64')}\n",
      "  warn(msg)\n",
      "/opt/conda/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: /usr/local/nvidia/lib:/usr/local/nvidia/lib64 did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...\n",
      "  warn(msg)\n",
      "/opt/conda/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('module'), PosixPath('//matplotlib_inline.backend_inline')}\n",
      "  warn(msg)\n",
      "/opt/conda/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/usr/local/cuda/lib64')}\n",
      "  warn(msg)\n",
      "/opt/conda/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: No libcudart.so found! Install CUDA or the cudatoolkit package (anaconda)!\n",
      "  warn(msg)\n",
      "INFO:torch.distributed.nn.jit.instantiator:Created a temporary directory at /tmp/tmpw8jbh8a_\n",
      "INFO:torch.distributed.nn.jit.instantiator:Writing /tmp/tmpw8jbh8a_/_remote_module_non_scriptable.py\n",
      "INFO:numexpr.utils:Note: NumExpr detected 32 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "INFO:numexpr.utils:NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "from transformers import Speech2TextProcessor, Speech2TextForConditionalGeneration\n",
    "from datasets import load_dataset\n",
    "from datasets import Audio\n",
    "import soundfile as sf\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from transformers import pipeline\n",
    "from transformers import AutoFeatureExtractor\n",
    "from transformers import Speech2Text2Processor, SpeechEncoderDecoderModel\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a6aa705",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type speech-encoder-decoder to instantiate a model of type speech_to_text. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of Speech2TextForConditionalGeneration were not initialized from the model checkpoint at facebook/s2t-wav2vec2-large-en-de and are newly initialized: ['decoder.layers.0.self_attn_layer_norm.bias', 'decoder.layers.3.self_attn.q_proj.bias', 'encoder.layers.10.fc2.bias', 'encoder.layers.8.self_attn.out_proj.weight', 'encoder.layers.9.self_attn.out_proj.bias', 'decoder.layers.3.self_attn.out_proj.bias', 'encoder.layers.0.fc1.bias', 'encoder.layers.0.self_attn_layer_norm.bias', 'decoder.layers.0.final_layer_norm.bias', 'encoder.layers.7.fc2.weight', 'encoder.layers.9.fc1.weight', 'decoder.layers.3.fc1.weight', 'encoder.layers.2.fc2.bias', 'encoder.layers.9.self_attn.q_proj.weight', 'encoder.layers.0.fc2.bias', 'decoder.layers.0.encoder_attn.k_proj.bias', 'encoder.layers.2.self_attn.v_proj.bias', 'encoder.layers.7.self_attn.v_proj.bias', 'encoder.layers.8.self_attn.q_proj.bias', 'decoder.layers.5.self_attn.out_proj.bias', 'decoder.layers.4.self_attn.out_proj.bias', 'decoder.layers.5.encoder_attn.out_proj.weight', 'decoder.layers.1.final_layer_norm.bias', 'decoder.layers.1.encoder_attn.out_proj.bias', 'encoder.layers.5.self_attn.k_proj.weight', 'encoder.layers.7.self_attn.q_proj.bias', 'decoder.layers.5.self_attn.out_proj.weight', 'encoder.layers.7.final_layer_norm.weight', 'encoder.layers.8.final_layer_norm.bias', 'encoder.layers.9.self_attn.q_proj.bias', 'encoder.layers.3.fc2.weight', 'decoder.layers.3.encoder_attn.k_proj.weight', 'encoder.layers.0.self_attn.k_proj.weight', 'encoder.layers.3.fc2.bias', 'decoder.layers.2.encoder_attn.v_proj.weight', 'encoder.layers.8.self_attn.k_proj.bias', 'decoder.layers.0.self_attn.k_proj.bias', 'decoder.layers.4.self_attn_layer_norm.bias', 'decoder.layers.3.final_layer_norm.weight', 'encoder.layers.11.self_attn.q_proj.weight', 'encoder.layers.8.fc1.weight', 'decoder.layers.2.self_attn_layer_norm.bias', 'encoder.layers.4.final_layer_norm.weight', 'encoder.layers.11.self_attn_layer_norm.weight', 'decoder.layers.4.encoder_attn.v_proj.bias', 'encoder.conv.conv_layers.0.bias', 'decoder.layers.1.encoder_attn.v_proj.weight', 'encoder.layers.9.self_attn.k_proj.bias', 'encoder.layers.1.self_attn_layer_norm.bias', 'encoder.layers.5.fc2.weight', 'encoder.layers.10.self_attn_layer_norm.bias', 'encoder.layers.11.self_attn.k_proj.bias', 'encoder.layers.2.self_attn.q_proj.weight', 'decoder.layers.2.encoder_attn.q_proj.bias', 'encoder.layers.6.self_attn.v_proj.bias', 'decoder.layers.0.self_attn_layer_norm.weight', 'encoder.layers.1.self_attn.k_proj.bias', 'decoder.layers.4.self_attn.k_proj.bias', 'encoder.layers.11.fc1.weight', 'encoder.layers.7.fc1.bias', 'encoder.layers.10.self_attn.v_proj.bias', 'encoder.layers.0.self_attn_layer_norm.weight', 'decoder.layers.5.encoder_attn.q_proj.bias', 'decoder.layers.3.encoder_attn.q_proj.weight', 'encoder.layers.8.self_attn_layer_norm.weight', 'decoder.layers.2.self_attn.out_proj.weight', 'encoder.layers.5.self_attn_layer_norm.bias', 'decoder.layers.2.fc1.bias', 'decoder.layers.1.encoder_attn_layer_norm.bias', 'decoder.layers.2.encoder_attn.v_proj.bias', 'encoder.layers.3.self_attn.v_proj.bias', 'encoder.layers.10.fc1.bias', 'decoder.layers.4.self_attn_layer_norm.weight', 'decoder.layers.3.fc1.bias', 'decoder.layers.4.encoder_attn.out_proj.weight', 'encoder.layers.7.self_attn.out_proj.bias', 'decoder.layers.3.encoder_attn.v_proj.weight', 'decoder.layers.5.final_layer_norm.weight', 'decoder.layers.5.final_layer_norm.bias', 'decoder.layers.5.encoder_attn_layer_norm.bias', 'encoder.layers.4.self_attn.out_proj.weight', 'encoder.layers.11.self_attn.out_proj.bias', 'decoder.layers.3.encoder_attn.out_proj.bias', 'decoder.layers.3.encoder_attn_layer_norm.bias', 'encoder.layers.4.self_attn.k_proj.weight', 'decoder.layers.4.encoder_attn.k_proj.bias', 'encoder.layers.10.self_attn.out_proj.weight', 'encoder.layers.5.self_attn.q_proj.weight', 'encoder.layers.2.self_attn.out_proj.weight', 'decoder.layers.4.final_layer_norm.weight', 'decoder.layers.0.fc2.weight', 'encoder.layers.3.self_attn_layer_norm.weight', 'decoder.layers.0.self_attn.q_proj.weight', 'encoder.layers.0.self_attn.k_proj.bias', 'decoder.layers.3.self_attn_layer_norm.bias', 'decoder.embed_tokens.weight', 'encoder.layers.2.self_attn.out_proj.bias', 'encoder.layers.3.final_layer_norm.bias', 'decoder.layers.1.fc1.bias', 'decoder.layers.4.fc2.bias', 'decoder.layers.5.encoder_attn.q_proj.weight', 'decoder.layers.4.encoder_attn_layer_norm.weight', 'decoder.layers.0.self_attn.v_proj.bias', 'encoder.layers.3.final_layer_norm.weight', 'encoder.layers.9.final_layer_norm.weight', 'decoder.layers.5.fc2.bias', 'encoder.layers.5.self_attn.v_proj.weight', 'encoder.layers.10.self_attn.q_proj.weight', 'encoder.layers.8.final_layer_norm.weight', 'encoder.layers.9.self_attn.out_proj.weight', 'decoder.layers.4.self_attn.q_proj.bias', 'encoder.layers.9.final_layer_norm.bias', 'encoder.layers.6.fc2.bias', 'decoder.layers.3.encoder_attn.v_proj.bias', 'encoder.layers.4.fc2.weight', 'encoder.layers.9.self_attn.k_proj.weight', 'encoder.layers.2.self_attn_layer_norm.weight', 'encoder.layers.0.final_layer_norm.bias', 'encoder.layers.8.fc2.bias', 'decoder.layers.5.self_attn_layer_norm.weight', 'encoder.layers.10.self_attn.q_proj.bias', 'encoder.layers.7.fc1.weight', 'decoder.layers.0.encoder_attn.out_proj.bias', 'encoder.layers.4.fc2.bias', 'decoder.layers.2.fc2.weight', 'decoder.layers.0.encoder_attn.q_proj.bias', 'decoder.layers.1.self_attn_layer_norm.bias', 'encoder.layers.6.self_attn.k_proj.bias', 'encoder.layers.6.final_layer_norm.bias', 'decoder.layers.0.fc1.weight', 'decoder.layers.0.encoder_attn.out_proj.weight', 'encoder.conv.conv_layers.1.weight', 'decoder.layers.2.encoder_attn.k_proj.weight', 'encoder.layers.10.self_attn.k_proj.bias', 'encoder.layers.6.fc2.weight', 'encoder.layers.3.self_attn_layer_norm.bias', 'decoder.layers.2.self_attn.v_proj.weight', 'encoder.layer_norm.bias', 'encoder.layers.10.self_attn.k_proj.weight', 'encoder.layers.8.self_attn_layer_norm.bias', 'encoder.layers.4.fc1.weight', 'decoder.layers.3.fc2.weight', 'encoder.layers.10.self_attn_layer_norm.weight', 'decoder.layers.4.self_attn.k_proj.weight', 'decoder.layers.2.fc1.weight', 'encoder.layers.10.self_attn.v_proj.weight', 'encoder.layers.9.self_attn.v_proj.bias', 'decoder.layers.3.fc2.bias', 'encoder.layers.0.self_attn.v_proj.bias', 'decoder.layers.2.self_attn.q_proj.weight', 'decoder.layers.3.self_attn_layer_norm.weight', 'decoder.layers.1.self_attn.q_proj.weight', 'encoder.layers.5.final_layer_norm.bias', 'encoder.layers.1.fc2.weight', 'decoder.layers.2.encoder_attn_layer_norm.bias', 'decoder.layers.0.self_attn.out_proj.weight', 'encoder.layers.11.self_attn.k_proj.weight', 'decoder.layers.1.encoder_attn.out_proj.weight', 'decoder.layers.3.final_layer_norm.bias', 'decoder.layers.4.encoder_attn.q_proj.bias', 'decoder.layers.5.encoder_attn_layer_norm.weight', 'decoder.layers.1.fc1.weight', 'encoder.layers.3.self_attn.q_proj.bias', 'decoder.layers.4.self_attn.v_proj.weight', 'encoder.layers.1.self_attn.out_proj.weight', 'encoder.layers.7.self_attn.out_proj.weight', 'decoder.layers.0.self_attn.out_proj.bias', 'encoder.layers.11.self_attn.out_proj.weight', 'encoder.layers.7.self_attn.k_proj.bias', 'decoder.layers.1.self_attn.k_proj.weight', 'decoder.layers.1.encoder_attn.k_proj.bias', 'decoder.layers.3.encoder_attn.k_proj.bias', 'encoder.layers.7.final_layer_norm.bias', 'encoder.layers.5.self_attn.k_proj.bias', 'decoder.layers.3.self_attn.k_proj.bias', 'encoder.layers.10.self_attn.out_proj.bias', 'decoder.layers.3.self_attn.out_proj.weight', 'decoder.layers.4.fc1.bias', 'encoder.layers.6.fc1.weight', 'encoder.layers.9.fc1.bias', 'decoder.layers.4.self_attn.v_proj.bias', 'encoder.layers.1.fc1.weight', 'encoder.layers.1.final_layer_norm.bias', 'encoder.layers.4.self_attn.out_proj.bias', 'encoder.layers.2.self_attn.v_proj.weight', 'decoder.layers.2.self_attn_layer_norm.weight', 'encoder.layers.11.self_attn.v_proj.bias', 'encoder.layers.2.fc2.weight', 'encoder.layers.5.self_attn.v_proj.bias', 'decoder.layers.1.encoder_attn.q_proj.weight', 'encoder.layers.6.self_attn.k_proj.weight', 'decoder.layers.1.fc2.weight', 'decoder.layers.4.fc2.weight', 'decoder.layers.1.encoder_attn.v_proj.bias', 'encoder.layers.5.self_attn_layer_norm.weight', 'encoder.layers.11.final_layer_norm.bias', 'decoder.layers.5.self_attn.v_proj.bias', 'encoder.layers.0.self_attn.out_proj.bias', 'encoder.layers.0.self_attn.out_proj.weight', 'encoder.layers.1.self_attn_layer_norm.weight', 'decoder.layers.4.self_attn.q_proj.weight', 'decoder.layers.4.fc1.weight', 'encoder.layers.4.self_attn.v_proj.weight', 'decoder.layers.5.fc2.weight', 'decoder.layer_norm.bias', 'encoder.layers.4.self_attn.q_proj.weight', 'encoder.layers.8.fc1.bias', 'decoder.layers.5.self_attn.v_proj.weight', 'encoder.layers.5.fc2.bias', 'decoder.layers.4.encoder_attn.out_proj.bias', 'decoder.layers.4.encoder_attn_layer_norm.bias', 'decoder.layers.4.final_layer_norm.bias', 'decoder.layers.4.encoder_attn.k_proj.weight', 'encoder.layers.4.self_attn.q_proj.bias', 'encoder.layers.2.fc1.weight', 'encoder.conv.conv_layers.0.weight', 'encoder.layers.8.self_attn.q_proj.weight', 'encoder.layers.10.final_layer_norm.bias', 'decoder.layer_norm.weight', 'encoder.layers.9.self_attn_layer_norm.weight', 'encoder.layers.3.self_attn.out_proj.bias', 'decoder.embed_positions.weights', 'encoder.layers.1.self_attn.v_proj.bias', 'encoder.layers.0.fc2.weight', 'decoder.layers.2.encoder_attn.out_proj.weight', 'encoder.layers.4.self_attn.v_proj.bias', 'encoder.layers.6.self_attn.out_proj.weight', 'encoder.layers.8.self_attn.v_proj.bias', 'encoder.layers.6.self_attn_layer_norm.weight', 'encoder.layers.5.self_attn.out_proj.weight', 'encoder.layers.2.final_layer_norm.weight', 'encoder.layers.0.self_attn.q_proj.bias', 'encoder.layers.10.fc1.weight', 'encoder.layers.5.final_layer_norm.weight', 'encoder.layers.4.final_layer_norm.bias', 'encoder.layers.7.self_attn.q_proj.weight', 'encoder.layers.8.self_attn.out_proj.bias', 'encoder.layers.11.fc2.weight', 'encoder.layers.2.fc1.bias', 'encoder.layers.9.fc2.bias', 'encoder.layers.6.self_attn.q_proj.bias', 'decoder.layers.3.self_attn.v_proj.weight', 'encoder.layers.0.self_attn.q_proj.weight', 'decoder.layers.3.self_attn.q_proj.weight', 'decoder.layers.1.self_attn.q_proj.bias', 'encoder.layers.1.self_attn.k_proj.weight', 'decoder.layers.0.encoder_attn_layer_norm.weight', 'decoder.layers.3.self_attn.k_proj.weight', 'decoder.layers.0.encoder_attn.v_proj.bias', 'decoder.layers.1.fc2.bias', 'encoder.layers.7.self_attn_layer_norm.weight', 'encoder.layers.2.self_attn_layer_norm.bias', 'encoder.layers.4.self_attn.k_proj.bias', 'decoder.layers.2.fc2.bias', 'encoder.layers.10.final_layer_norm.weight', 'encoder.layers.1.fc2.bias', 'decoder.layers.0.self_attn.v_proj.weight', 'decoder.layers.2.self_attn.k_proj.weight', 'decoder.layers.2.self_attn.v_proj.bias', 'lm_head.weight', 'decoder.layers.0.final_layer_norm.weight', 'encoder.layers.7.self_attn_layer_norm.bias', 'encoder.layers.11.self_attn.v_proj.weight', 'encoder.layers.4.self_attn_layer_norm.bias', 'decoder.layers.5.self_attn.q_proj.weight', 'decoder.layers.5.encoder_attn.v_proj.bias', 'decoder.layers.3.encoder_attn.q_proj.bias', 'encoder.layers.0.self_attn.v_proj.weight', 'decoder.layers.0.self_attn.q_proj.bias', 'decoder.layers.5.encoder_attn.v_proj.weight', 'encoder.layers.11.fc2.bias', 'decoder.layers.3.encoder_attn.out_proj.weight', 'decoder.layers.0.encoder_attn_layer_norm.bias', 'decoder.layers.1.self_attn.v_proj.weight', 'encoder.layers.11.fc1.bias', 'encoder.layers.1.self_attn.out_proj.bias', 'encoder.layers.6.self_attn.out_proj.bias', 'decoder.layers.5.fc1.weight', 'encoder.layers.4.fc1.bias', 'encoder.layers.3.self_attn.k_proj.weight', 'decoder.layers.5.self_attn.k_proj.weight', 'encoder.layers.1.self_attn.q_proj.bias', 'decoder.layers.0.self_attn.k_proj.weight', 'decoder.layers.4.self_attn.out_proj.weight', 'decoder.layers.0.encoder_attn.v_proj.weight', 'decoder.layers.5.self_attn_layer_norm.bias', 'encoder.layers.3.self_attn.out_proj.weight', 'encoder.conv.conv_layers.1.bias', 'encoder.layers.10.fc2.weight', 'encoder.layers.1.self_attn.q_proj.weight', 'encoder.layers.6.fc1.bias', 'decoder.layers.2.self_attn.q_proj.bias', 'encoder.layers.11.self_attn.q_proj.bias', 'encoder.layers.11.final_layer_norm.weight', 'encoder.embed_positions.weights', 'decoder.layers.1.encoder_attn.k_proj.weight', 'encoder.layers.3.self_attn.k_proj.bias', 'encoder.layers.5.self_attn.out_proj.bias', 'encoder.layers.7.self_attn.v_proj.weight', 'encoder.layers.9.self_attn_layer_norm.bias', 'decoder.layers.0.encoder_attn.q_proj.weight', 'encoder.layers.6.final_layer_norm.weight', 'decoder.layers.4.encoder_attn.q_proj.weight', 'decoder.layers.1.self_attn.v_proj.bias', 'encoder.layers.7.fc2.bias', 'encoder.layers.6.self_attn.v_proj.weight', 'encoder.layers.2.self_attn.q_proj.bias', 'encoder.layers.4.self_attn_layer_norm.weight', 'decoder.layers.2.final_layer_norm.bias', 'encoder.layers.5.self_attn.q_proj.bias', 'encoder.layers.2.self_attn.k_proj.weight', 'encoder.layers.5.fc1.bias', 'decoder.layers.2.final_layer_norm.weight', 'decoder.layers.0.fc1.bias', 'encoder.layers.1.fc1.bias', 'decoder.layers.5.encoder_attn.out_proj.bias', 'decoder.layers.5.fc1.bias', 'decoder.layers.2.encoder_attn_layer_norm.weight', 'encoder.layers.6.self_attn.q_proj.weight', 'encoder.layers.3.self_attn.v_proj.weight', 'encoder.layers.9.self_attn.v_proj.weight', 'decoder.layers.5.encoder_attn.k_proj.weight', 'decoder.layers.1.self_attn.k_proj.bias', 'decoder.layers.1.self_attn_layer_norm.weight', 'encoder.layers.3.fc1.bias', 'decoder.layers.0.encoder_attn.k_proj.weight', 'decoder.layers.5.self_attn.q_proj.bias', 'encoder.layers.8.self_attn.v_proj.weight', 'encoder.layers.3.fc1.weight', 'encoder.layers.8.self_attn.k_proj.weight', 'encoder.layers.2.final_layer_norm.bias', 'encoder.layers.1.self_attn.v_proj.weight', 'encoder.layers.6.self_attn_layer_norm.bias', 'encoder.layers.2.self_attn.k_proj.bias', 'decoder.layers.2.self_attn.k_proj.bias', 'decoder.layers.3.encoder_attn_layer_norm.weight', 'encoder.layer_norm.weight', 'encoder.layers.9.fc2.weight', 'decoder.layers.5.self_attn.k_proj.bias', 'decoder.layers.2.encoder_attn.k_proj.bias', 'encoder.layers.5.fc1.weight', 'encoder.layers.0.final_layer_norm.weight', 'encoder.layers.3.self_attn.q_proj.weight', 'decoder.layers.0.fc2.bias', 'encoder.layers.1.final_layer_norm.weight', 'encoder.layers.8.fc2.weight', 'decoder.layers.4.encoder_attn.v_proj.weight', 'decoder.layers.2.encoder_attn.q_proj.weight', 'decoder.layers.2.self_attn.out_proj.bias', 'encoder.layers.7.self_attn.k_proj.weight', 'decoder.layers.2.encoder_attn.out_proj.bias', 'encoder.layers.11.self_attn_layer_norm.bias', 'decoder.layers.1.encoder_attn.q_proj.bias', 'decoder.layers.1.final_layer_norm.weight', 'decoder.layers.1.self_attn.out_proj.weight', 'decoder.layers.3.self_attn.v_proj.bias', 'encoder.layers.0.fc1.weight', 'decoder.layers.1.self_attn.out_proj.bias', 'decoder.layers.1.encoder_attn_layer_norm.weight', 'decoder.layers.5.encoder_attn.k_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"facebook/s2t-wav2vec2-large-en-de\"\n",
    "model = Speech2TextForConditionalGeneration.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63bc9c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = Speech2TextProcessor.from_pretrained(\"facebook/s2t-small-librispeech-asr\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "947aa11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_array(batch):\n",
    "    speech, _ = sf.read(batch[\"path\"])\n",
    "    batch[\"speech\"] = speech\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "90822393",
   "metadata": {},
   "outputs": [],
   "source": [
    "minds = load_dataset(\"PolyAI/minds14\", name=\"en-US\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0fa06e1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['path', 'audio', 'transcription', 'english_transcription', 'intent_class', 'lang_id'],\n",
       "    num_rows: 563\n",
       "})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "96e508f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = minds.map(map_to_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "14e1016e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.remove_columns([\"path\", \"transcription\", \"english_transcription\", \"lang_id\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b84e0002",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.cast_column(\"audio\", Audio(sampling_rate=16_000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "01d03517",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.rename_column(\"intent_class\", \"label\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d648718e",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ds.features[\"label\"].names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "86f056ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "label2id, id2label = dict(), dict()\n",
    "for i, label in enumerate(labels):\n",
    "    label2id[label] = str(i)\n",
    "    id2label[str(i)] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6a58fbfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': 'abroad',\n",
       " '1': 'address',\n",
       " '2': 'app_error',\n",
       " '3': 'atm_limit',\n",
       " '4': 'balance',\n",
       " '5': 'business_loan',\n",
       " '6': 'card_issues',\n",
       " '7': 'cash_deposit',\n",
       " '8': 'direct_debit',\n",
       " '9': 'freeze',\n",
       " '10': 'high_value_payment',\n",
       " '11': 'joint_account',\n",
       " '12': 'latest_transactions',\n",
       " '13': 'pay_bill'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "86231b3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "24951255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e949bec22c34598b1e8ad02615a937d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)rocessor_config.json:   0%|          | 0.00/212 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_extractor = AutoFeatureExtractor.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2be38f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    audio_arrays = [x[\"array\"] for x in examples[\"audio\"]]\n",
    "    inputs = feature_extractor(\n",
    "        audio_arrays, sampling_rate=feature_extractor.sampling_rate, max_length=16000, truncation=True\n",
    "    )\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8c3a5253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74d817c8d442499fa3e3dab123f469bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/563 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds_T = ds.map(preprocess_function, remove_columns=\"audio\", batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8d88c93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c0e2ffe9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e303efca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions = np.argmax(eval_pred.predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=eval_pred.label_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "70d65035",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file = ds[0][\"audio\"][\"path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6129c01a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/root/.cache/huggingface/datasets/downloads/extracted/a19fbc5032eacf25eab0097832db7b7f022b42104fbad6bd5765527704a428b9/en-US~JOINT_ACCOUNT/602ba55abb1e6d0fbce92065.wav'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa80d35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f937ed74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ade9157e",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = pipeline(\"audio-classification\", model=\"stevhliu/my_awesome_minds_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21dbeb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier(audio_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d24adc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26fd100",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d0ce2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b04bdd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6695385d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986dde1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de46dbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47994800",
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.display(IPython.display.Audio(audio_file, rate=22050, autoplay=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698f4725",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
