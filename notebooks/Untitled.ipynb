{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcffee33",
   "metadata": {},
   "source": [
    "Source: https://huggingface.co/TheBloke/Pygmalion-13B-SuperHOT-8K-GPTQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc496833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\r\n",
      "Copyright (c) 2005-2019 NVIDIA Corporation\r\n",
      "Built on Sun_Jul_28_19:07:16_PDT_2019\r\n",
      "Cuda compilation tools, release 10.1, V10.1.243\r\n"
     ]
    }
   ],
   "source": [
    "!nvcc -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd57e13d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Jul  2 14:42:57 2023       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 525.116.04   Driver Version: 525.116.04   CUDA Version: 12.0     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0 Off |                  Off |\r\n",
      "|  0%   43C    P8    17W / 480W |      3MiB / 24564MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "926e862d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1+cu118\r\n"
     ]
    }
   ],
   "source": [
    "!python3 -c \"import torch; print(torch.__version__)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "891033bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Name                    Version                   Build  Channel\n",
      "cudatoolkit               11.8.0               h6a678d5_0  \n",
      "torch                     2.0.1+cu118              pypi_0    pypi\n",
      "torchaudio                2.0.2+cu118              pypi_0    pypi\n",
      "torchvision               0.15.2+cu118             pypi_0    pypi\n"
     ]
    }
   ],
   "source": [
    "!conda list | sed -n \"3p\" && conda list | grep -i -E \"cuda|torch\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e975c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6d649d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: einops in /opt/conda/lib/python3.10/site-packages (0.6.1)\n",
      "Collecting auto-gptq\n",
      "  Using cached auto_gptq-0.2.2.tar.gz (52 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: accelerate>=0.19.0 in /opt/conda/lib/python3.10/site-packages (from auto-gptq) (0.21.0.dev0)\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (from auto-gptq) (2.13.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from auto-gptq) (1.24.3)\n",
      "Requirement already satisfied: rouge in /opt/conda/lib/python3.10/site-packages (from auto-gptq) (1.0.1)\n",
      "Requirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from auto-gptq) (2.0.1+cu118)\n",
      "Requirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from auto-gptq) (0.3.1)\n",
      "Requirement already satisfied: transformers>=4.26.1 in /opt/conda/lib/python3.10/site-packages (from auto-gptq) (4.31.0.dev0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.19.0->auto-gptq) (23.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.19.0->auto-gptq) (6.0)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.19.0->auto-gptq) (5.9.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (1.11.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (3.0)\n",
      "Requirement already satisfied: triton==2.0.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (2.0.0)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (3.1.2)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (4.4.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (3.9.0)\n",
      "Requirement already satisfied: lit in /opt/conda/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.13.0->auto-gptq) (15.0.7)\n",
      "Requirement already satisfied: cmake in /opt/conda/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.13.0->auto-gptq) (3.25.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.26.1->auto-gptq) (0.13.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.26.1->auto-gptq) (0.15.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.26.1->auto-gptq) (2023.6.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.26.1->auto-gptq) (4.65.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers>=4.26.1->auto-gptq) (2.29.0)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /opt/conda/lib/python3.10/site-packages (from datasets->auto-gptq) (2023.6.0)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets->auto-gptq) (0.70.14)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets->auto-gptq) (12.0.1)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets->auto-gptq) (2.0.2)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets->auto-gptq) (3.8.4)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets->auto-gptq) (3.2.0)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets->auto-gptq) (0.3.6)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from rouge->auto-gptq) (1.16.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->auto-gptq) (6.0.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->auto-gptq) (1.3.3)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->auto-gptq) (2.0.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->auto-gptq) (23.1.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->auto-gptq) (4.0.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->auto-gptq) (1.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->auto-gptq) (1.9.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.26.1->auto-gptq) (1.26.16)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.26.1->auto-gptq) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.26.1->auto-gptq) (2023.5.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->auto-gptq) (2.1.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->auto-gptq) (2022.7)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->auto-gptq) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->auto-gptq) (2.8.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->auto-gptq) (1.2.1)\n",
      "Building wheels for collected packages: auto-gptq\n",
      "  Building wheel for auto-gptq (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[106 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m include dirs are: ['autogptq_cuda']\n",
      "  \u001b[31m   \u001b[0m running bdist_wheel\n",
      "  \u001b[31m   \u001b[0m /opt/conda/lib/python3.10/site-packages/torch/utils/cpp_extension.py:476: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
      "  \u001b[31m   \u001b[0m   warnings.warn(msg.format('we could not find ninja.'))\n",
      "  \u001b[31m   \u001b[0m running build\n",
      "  \u001b[31m   \u001b[0m running build_py\n",
      "  \u001b[31m   \u001b[0m creating build\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-310\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-310/auto_gptq\n",
      "  \u001b[31m   \u001b[0m copying auto_gptq/__init__.py -> build/lib.linux-x86_64-cpython-310/auto_gptq\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-310/auto_gptq/eval_tasks\n",
      "  \u001b[31m   \u001b[0m copying auto_gptq/eval_tasks/_base.py -> build/lib.linux-x86_64-cpython-310/auto_gptq/eval_tasks\n",
      "  \u001b[31m   \u001b[0m copying auto_gptq/eval_tasks/language_modeling_task.py -> build/lib.linux-x86_64-cpython-310/auto_gptq/eval_tasks\n",
      "  \u001b[31m   \u001b[0m copying auto_gptq/eval_tasks/__init__.py -> build/lib.linux-x86_64-cpython-310/auto_gptq/eval_tasks\n",
      "  \u001b[31m   \u001b[0m copying auto_gptq/eval_tasks/sequence_classification_task.py -> build/lib.linux-x86_64-cpython-310/auto_gptq/eval_tasks\n",
      "  \u001b[31m   \u001b[0m copying auto_gptq/eval_tasks/text_summarization_task.py -> build/lib.linux-x86_64-cpython-310/auto_gptq/eval_tasks\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-310/auto_gptq/modeling\n",
      "  \u001b[31m   \u001b[0m copying auto_gptq/modeling/_base.py -> build/lib.linux-x86_64-cpython-310/auto_gptq/modeling\n",
      "  \u001b[31m   \u001b[0m copying auto_gptq/modeling/gpt_bigcode.py -> build/lib.linux-x86_64-cpython-310/auto_gptq/modeling\n",
      "  \u001b[31m   \u001b[0m copying auto_gptq/modeling/llama.py -> build/lib.linux-x86_64-cpython-310/auto_gptq/modeling\n",
      "  \u001b[31m   \u001b[0m copying auto_gptq/modeling/moss.py -> build/lib.linux-x86_64-cpython-310/auto_gptq/modeling\n",
      "  \u001b[31m   \u001b[0m copying auto_gptq/modeling/bloom.py -> build/lib.linux-x86_64-cpython-310/auto_gptq/modeling\n",
      "  \u001b[31m   \u001b[0m copying auto_gptq/modeling/_utils.py -> build/lib.linux-x86_64-cpython-310/auto_gptq/modeling\n",
      "  \u001b[31m   \u001b[0m copying auto_gptq/modeling/_const.py -> build/lib.linux-x86_64-cpython-310/auto_gptq/modeling\n",
      "  \u001b[31m   \u001b[0m copying auto_gptq/modeling/__init__.py -> build/lib.linux-x86_64-cpython-310/auto_gptq/modeling\n",
      "  \u001b[31m   \u001b[0m copying auto_gptq/modeling/auto.py -> build/lib.linux-x86_64-cpython-310/auto_gptq/modeling\n",
      "  \u001b[31m   \u001b[0m copying auto_gptq/modeling/gpt_neox.py -> build/lib.linux-x86_64-cpython-310/auto_gptq/modeling\n",
      "  \u001b[31m   \u001b[0m copying auto_gptq/modeling/gpt2.py -> build/lib.linux-x86_64-cpython-310/auto_gptq/modeling\n",
      "  \u001b[31m   \u001b[0m copying auto_gptq/modeling/codegen.py -> build/lib.linux-x86_64-cpython-310/auto_gptq/modeling\n",
      "  \u001b[31m   \u001b[0m copying auto_gptq/modeling/opt.py -> build/lib.linux-x86_64-cpython-310/auto_gptq/modeling\n",
      "  \u001b[31m   \u001b[0m copying auto_gptq/modeling/rw.py -> build/lib.linux-x86_64-cpython-310/auto_gptq/modeling\n",
      "  \u001b[31m   \u001b[0m copying auto_gptq/modeling/gptj.py -> build/lib.linux-x86_64-cpython-310/auto_gptq/modeling\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-310/auto_gptq/nn_modules\n",
      "  \u001b[31m   \u001b[0m copying auto_gptq/nn_modules/qlinear.py -> build/lib.linux-x86_64-cpython-310/auto_gptq/nn_modules\n",
      "  \u001b[31m   \u001b[0m copying auto_gptq/nn_modules/qlinear_old.py -> build/lib.linux-x86_64-cpython-310/auto_gptq/nn_modules\n",
      "  \u001b[31m   \u001b[0m copying auto_gptq/nn_modules/_fused_base.py -> build/lib.linux-x86_64-cpython-310/auto_gptq/nn_modules\n",
      "  \u001b[31m   \u001b[0m copying auto_gptq/nn_modules/qlinear_triton.py -> build/lib.linux-x86_64-cpython-310/auto_gptq/nn_modules\n",
      "  \u001b[31m   \u001b[0m copying auto_gptq/nn_modules/fused_gptj_attn.py -> build/lib.linux-x86_64-cpython-310/auto_gptq/nn_modules\n",
      "  \u001b[31m   \u001b[0m copying auto_gptq/nn_modules/__init__.py -> build/lib.linux-x86_64-cpython-310/auto_gptq/nn_modules\n",
      "  \u001b[31m   \u001b[0m copying auto_gptq/nn_modules/fused_llama_attn.py -> build/lib.linux-x86_64-cpython-310/auto_gptq/nn_modules\n",
      "  \u001b[31m   \u001b[0m copying auto_gptq/nn_modules/fused_llama_mlp.py -> build/lib.linux-x86_64-cpython-310/auto_gptq/nn_modules\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-310/auto_gptq/quantization\n",
      "  \u001b[31m   \u001b[0m copying auto_gptq/quantization/gptq.py -> build/lib.linux-x86_64-cpython-310/auto_gptq/quantization\n",
      "  \u001b[31m   \u001b[0m copying auto_gptq/quantization/quantizer.py -> build/lib.linux-x86_64-cpython-310/auto_gptq/quantization\n",
      "  \u001b[31m   \u001b[0m copying auto_gptq/quantization/__init__.py -> build/lib.linux-x86_64-cpython-310/auto_gptq/quantization\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-310/auto_gptq/utils\n",
      "  \u001b[31m   \u001b[0m copying auto_gptq/utils/data_utils.py -> build/lib.linux-x86_64-cpython-310/auto_gptq/utils\n",
      "  \u001b[31m   \u001b[0m copying auto_gptq/utils/__init__.py -> build/lib.linux-x86_64-cpython-310/auto_gptq/utils\n",
      "  \u001b[31m   \u001b[0m copying auto_gptq/utils/import_utils.py -> build/lib.linux-x86_64-cpython-310/auto_gptq/utils\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-310/auto_gptq/eval_tasks/_utils\n",
      "  \u001b[31m   \u001b[0m copying auto_gptq/eval_tasks/_utils/__init__.py -> build/lib.linux-x86_64-cpython-310/auto_gptq/eval_tasks/_utils\n",
      "  \u001b[31m   \u001b[0m copying auto_gptq/eval_tasks/_utils/classification_utils.py -> build/lib.linux-x86_64-cpython-310/auto_gptq/eval_tasks/_utils\n",
      "  \u001b[31m   \u001b[0m copying auto_gptq/eval_tasks/_utils/generation_utils.py -> build/lib.linux-x86_64-cpython-310/auto_gptq/eval_tasks/_utils\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-310/auto_gptq/nn_modules/triton_utils\n",
      "  \u001b[31m   \u001b[0m copying auto_gptq/nn_modules/triton_utils/custom_autotune.py -> build/lib.linux-x86_64-cpython-310/auto_gptq/nn_modules/triton_utils\n",
      "  \u001b[31m   \u001b[0m copying auto_gptq/nn_modules/triton_utils/kernels.py -> build/lib.linux-x86_64-cpython-310/auto_gptq/nn_modules/triton_utils\n",
      "  \u001b[31m   \u001b[0m copying auto_gptq/nn_modules/triton_utils/mixin.py -> build/lib.linux-x86_64-cpython-310/auto_gptq/nn_modules/triton_utils\n",
      "  \u001b[31m   \u001b[0m copying auto_gptq/nn_modules/triton_utils/__init__.py -> build/lib.linux-x86_64-cpython-310/auto_gptq/nn_modules/triton_utils\n",
      "  \u001b[31m   \u001b[0m running build_ext\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-sghi0fvp/auto-gptq_66d690ffbdad42e2af3716d6110c2bb7/setup.py\", line 92, in <module>\n",
      "  \u001b[31m   \u001b[0m     setup(\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/__init__.py\", line 87, in setup\n",
      "  \u001b[31m   \u001b[0m     return distutils.core.setup(**attrs)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/_distutils/core.py\", line 185, in setup\n",
      "  \u001b[31m   \u001b[0m     return run_commands(dist)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/_distutils/core.py\", line 201, in run_commands\n",
      "  \u001b[31m   \u001b[0m     dist.run_commands()\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/_distutils/dist.py\", line 969, in run_commands\n",
      "  \u001b[31m   \u001b[0m     self.run_command(cmd)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/dist.py\", line 1208, in run_command\n",
      "  \u001b[31m   \u001b[0m     super().run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/_distutils/dist.py\", line 988, in run_command\n",
      "  \u001b[31m   \u001b[0m     cmd_obj.run()\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/wheel/bdist_wheel.py\", line 325, in run\n",
      "  \u001b[31m   \u001b[0m     self.run_command(\"build\")\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/_distutils/cmd.py\", line 318, in run_command\n",
      "  \u001b[31m   \u001b[0m     self.distribution.run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/dist.py\", line 1208, in run_command\n",
      "  \u001b[31m   \u001b[0m     super().run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/_distutils/dist.py\", line 988, in run_command\n",
      "  \u001b[31m   \u001b[0m     cmd_obj.run()\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/_distutils/command/build.py\", line 132, in run\n",
      "  \u001b[31m   \u001b[0m     self.run_command(cmd_name)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/_distutils/cmd.py\", line 318, in run_command\n",
      "  \u001b[31m   \u001b[0m     self.distribution.run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/dist.py\", line 1208, in run_command\n",
      "  \u001b[31m   \u001b[0m     super().run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/_distutils/dist.py\", line 988, in run_command\n",
      "  \u001b[31m   \u001b[0m     cmd_obj.run()\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/command/build_ext.py\", line 84, in run\n",
      "  \u001b[31m   \u001b[0m     _build_ext.run(self)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/Cython/Distutils/old_build_ext.py\", line 186, in run\n",
      "  \u001b[31m   \u001b[0m     _build_ext.build_ext.run(self)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/_distutils/command/build_ext.py\", line 346, in run\n",
      "  \u001b[31m   \u001b[0m     self.build_extensions()\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/torch/utils/cpp_extension.py\", line 499, in build_extensions\n",
      "  \u001b[31m   \u001b[0m     _check_cuda_version(compiler_name, compiler_version)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/torch/utils/cpp_extension.py\", line 387, in _check_cuda_version\n",
      "  \u001b[31m   \u001b[0m     raise RuntimeError(CUDA_MISMATCH_MESSAGE.format(cuda_str_version, torch.version.cuda))\n",
      "  \u001b[31m   \u001b[0m RuntimeError:\n",
      "  \u001b[31m   \u001b[0m The detected CUDA version (10.1) mismatches the version that was used to compile\n",
      "  \u001b[31m   \u001b[0m PyTorch (11.8). Please make sure to use the same CUDA versions.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[31m  ERROR: Failed building wheel for auto-gptq\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[?25h  Running setup.py clean for auto-gptq\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to build auto-gptq\n",
      "Installing collected packages: auto-gptq\n",
      "  Running setup.py install for auto-gptq ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mRunning setup.py install for auto-gptq\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[110 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m include dirs are: ['autogptq_cuda']\n",
      "  \u001b[31m   \u001b[0m running install\n",
      "  \u001b[31m   \u001b[0m /opt/conda/lib/python3.10/site-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "  \u001b[31m   \u001b[0m   warnings.warn(\n",
      "  \u001b[31m   \u001b[0m running build\n",
      "  \u001b[31m   \u001b[0m running build_py\n",
      "  \u001b[31m   \u001b[0m creating build\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-310\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-310/auto_gptq\n",
      "  \u001b[31m   \u001b[0m copying auto_gptq/__init__.py -> build/lib.linux-x86_64-cpython-310/auto_gptq\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-310/auto_gptq/eval_tasks\n",
      "  \u001b[31m   \u001b[0m copying auto_gptq/eval_tasks/_base.py -> build/lib.linux-x86_64-cpython-310/auto_gptq/eval_tasks\n",
      "  \u001b[31m   \u001b[0m copying auto_gptq/eval_tasks/language_modeling_task.py -> build/lib.linux-x86_64-cpython-310/auto_gptq/eval_tasks\n",
      "  \u001b[31m   \u001b[0m copying auto_gptq/eval_tasks/__init__.py -> build/lib.linux-x86_64-cpython-310/auto_gptq/eval_tasks\n",
      "  \u001b[31m   \u001b[0m copying auto_gptq/eval_tasks/sequence_classification_task.py -> build/lib.linux-x86_64-cpython-310/auto_gptq/eval_tasks\n",
      "  \u001b[31m   \u001b[0m copying auto_gptq/eval_tasks/text_summarization_task.py -> build/lib.linux-x86_64-cpython-310/auto_gptq/eval_tasks\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-310/auto_gptq/modeling\n",
      "  \u001b[31m   \u001b[0m copying auto_gptq/modeling/_base.py -> build/lib.linux-x86_64-cpython-310/auto_gptq/modeling\n",
      "  \u001b[31m   \u001b[0m copying auto_gptq/modeling/gpt_bigcode.py -> build/lib.linux-x86_64-cpython-310/auto_gptq/modeling\n",
      "  \u001b[31m   \u001b[0m copying auto_gptq/modeling/llama.py -> build/lib.linux-x86_64-cpython-310/auto_gptq/modeling\n",
      "  \u001b[31m   \u001b[0m copying auto_gptq/modeling/moss.py -> build/lib.linux-x86_64-cpython-310/auto_gptq/modeling\n",
      "  \u001b[31m   \u001b[0m copying auto_gptq/modeling/bloom.py -> build/lib.linux-x86_64-cpython-310/auto_gptq/modeling\n",
      "  \u001b[31m   \u001b[0m copying auto_gptq/modeling/_utils.py -> build/lib.linux-x86_64-cpython-310/auto_gptq/modeling\n",
      "  \u001b[31m   \u001b[0m copying auto_gptq/modeling/_const.py -> build/lib.linux-x86_64-cpython-310/auto_gptq/modeling\n",
      "  \u001b[31m   \u001b[0m copying auto_gptq/modeling/__init__.py -> build/lib.linux-x86_64-cpython-310/auto_gptq/modeling\n",
      "  \u001b[31m   \u001b[0m copying auto_gptq/modeling/auto.py -> build/lib.linux-x86_64-cpython-310/auto_gptq/modeling\n",
      "  \u001b[31m   \u001b[0m copying auto_gptq/modeling/gpt_neox.py -> build/lib.linux-x86_64-cpython-310/auto_gptq/modeling\n",
      "  \u001b[31m   \u001b[0m copying auto_gptq/modeling/gpt2.py -> build/lib.linux-x86_64-cpython-310/auto_gptq/modeling\n",
      "  \u001b[31m   \u001b[0m copying auto_gptq/modeling/codegen.py -> build/lib.linux-x86_64-cpython-310/auto_gptq/modeling\n",
      "  \u001b[31m   \u001b[0m copying auto_gptq/modeling/opt.py -> build/lib.linux-x86_64-cpython-310/auto_gptq/modeling\n",
      "  \u001b[31m   \u001b[0m copying auto_gptq/modeling/rw.py -> build/lib.linux-x86_64-cpython-310/auto_gptq/modeling\n",
      "  \u001b[31m   \u001b[0m copying auto_gptq/modeling/gptj.py -> build/lib.linux-x86_64-cpython-310/auto_gptq/modeling\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-310/auto_gptq/nn_modules\n",
      "  \u001b[31m   \u001b[0m copying auto_gptq/nn_modules/qlinear.py -> build/lib.linux-x86_64-cpython-310/auto_gptq/nn_modules\n",
      "  \u001b[31m   \u001b[0m copying auto_gptq/nn_modules/qlinear_old.py -> build/lib.linux-x86_64-cpython-310/auto_gptq/nn_modules\n",
      "  \u001b[31m   \u001b[0m copying auto_gptq/nn_modules/_fused_base.py -> build/lib.linux-x86_64-cpython-310/auto_gptq/nn_modules\n",
      "  \u001b[31m   \u001b[0m copying auto_gptq/nn_modules/qlinear_triton.py -> build/lib.linux-x86_64-cpython-310/auto_gptq/nn_modules\n",
      "  \u001b[31m   \u001b[0m copying auto_gptq/nn_modules/fused_gptj_attn.py -> build/lib.linux-x86_64-cpython-310/auto_gptq/nn_modules\n",
      "  \u001b[31m   \u001b[0m copying auto_gptq/nn_modules/__init__.py -> build/lib.linux-x86_64-cpython-310/auto_gptq/nn_modules\n",
      "  \u001b[31m   \u001b[0m copying auto_gptq/nn_modules/fused_llama_attn.py -> build/lib.linux-x86_64-cpython-310/auto_gptq/nn_modules\n",
      "  \u001b[31m   \u001b[0m copying auto_gptq/nn_modules/fused_llama_mlp.py -> build/lib.linux-x86_64-cpython-310/auto_gptq/nn_modules\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-310/auto_gptq/quantization\n",
      "  \u001b[31m   \u001b[0m copying auto_gptq/quantization/gptq.py -> build/lib.linux-x86_64-cpython-310/auto_gptq/quantization\n",
      "  \u001b[31m   \u001b[0m copying auto_gptq/quantization/quantizer.py -> build/lib.linux-x86_64-cpython-310/auto_gptq/quantization\n",
      "  \u001b[31m   \u001b[0m copying auto_gptq/quantization/__init__.py -> build/lib.linux-x86_64-cpython-310/auto_gptq/quantization\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-310/auto_gptq/utils\n",
      "  \u001b[31m   \u001b[0m copying auto_gptq/utils/data_utils.py -> build/lib.linux-x86_64-cpython-310/auto_gptq/utils\n",
      "  \u001b[31m   \u001b[0m copying auto_gptq/utils/__init__.py -> build/lib.linux-x86_64-cpython-310/auto_gptq/utils\n",
      "  \u001b[31m   \u001b[0m copying auto_gptq/utils/import_utils.py -> build/lib.linux-x86_64-cpython-310/auto_gptq/utils\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-310/auto_gptq/eval_tasks/_utils\n",
      "  \u001b[31m   \u001b[0m copying auto_gptq/eval_tasks/_utils/__init__.py -> build/lib.linux-x86_64-cpython-310/auto_gptq/eval_tasks/_utils\n",
      "  \u001b[31m   \u001b[0m copying auto_gptq/eval_tasks/_utils/classification_utils.py -> build/lib.linux-x86_64-cpython-310/auto_gptq/eval_tasks/_utils\n",
      "  \u001b[31m   \u001b[0m copying auto_gptq/eval_tasks/_utils/generation_utils.py -> build/lib.linux-x86_64-cpython-310/auto_gptq/eval_tasks/_utils\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-310/auto_gptq/nn_modules/triton_utils\n",
      "  \u001b[31m   \u001b[0m copying auto_gptq/nn_modules/triton_utils/custom_autotune.py -> build/lib.linux-x86_64-cpython-310/auto_gptq/nn_modules/triton_utils\n",
      "  \u001b[31m   \u001b[0m copying auto_gptq/nn_modules/triton_utils/kernels.py -> build/lib.linux-x86_64-cpython-310/auto_gptq/nn_modules/triton_utils\n",
      "  \u001b[31m   \u001b[0m copying auto_gptq/nn_modules/triton_utils/mixin.py -> build/lib.linux-x86_64-cpython-310/auto_gptq/nn_modules/triton_utils\n",
      "  \u001b[31m   \u001b[0m copying auto_gptq/nn_modules/triton_utils/__init__.py -> build/lib.linux-x86_64-cpython-310/auto_gptq/nn_modules/triton_utils\n",
      "  \u001b[31m   \u001b[0m running build_ext\n",
      "  \u001b[31m   \u001b[0m /opt/conda/lib/python3.10/site-packages/torch/utils/cpp_extension.py:476: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
      "  \u001b[31m   \u001b[0m   warnings.warn(msg.format('we could not find ninja.'))\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-sghi0fvp/auto-gptq_66d690ffbdad42e2af3716d6110c2bb7/setup.py\", line 92, in <module>\n",
      "  \u001b[31m   \u001b[0m     setup(\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/__init__.py\", line 87, in setup\n",
      "  \u001b[31m   \u001b[0m     return distutils.core.setup(**attrs)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/_distutils/core.py\", line 185, in setup\n",
      "  \u001b[31m   \u001b[0m     return run_commands(dist)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/_distutils/core.py\", line 201, in run_commands\n",
      "  \u001b[31m   \u001b[0m     dist.run_commands()\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/_distutils/dist.py\", line 969, in run_commands\n",
      "  \u001b[31m   \u001b[0m     self.run_command(cmd)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/dist.py\", line 1208, in run_command\n",
      "  \u001b[31m   \u001b[0m     super().run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/_distutils/dist.py\", line 988, in run_command\n",
      "  \u001b[31m   \u001b[0m     cmd_obj.run()\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/command/install.py\", line 68, in run\n",
      "  \u001b[31m   \u001b[0m     return orig.install.run(self)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/_distutils/command/install.py\", line 698, in run\n",
      "  \u001b[31m   \u001b[0m     self.run_command('build')\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/_distutils/cmd.py\", line 318, in run_command\n",
      "  \u001b[31m   \u001b[0m     self.distribution.run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/dist.py\", line 1208, in run_command\n",
      "  \u001b[31m   \u001b[0m     super().run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/_distutils/dist.py\", line 988, in run_command\n",
      "  \u001b[31m   \u001b[0m     cmd_obj.run()\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/_distutils/command/build.py\", line 132, in run\n",
      "  \u001b[31m   \u001b[0m     self.run_command(cmd_name)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/_distutils/cmd.py\", line 318, in run_command\n",
      "  \u001b[31m   \u001b[0m     self.distribution.run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/dist.py\", line 1208, in run_command\n",
      "  \u001b[31m   \u001b[0m     super().run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/_distutils/dist.py\", line 988, in run_command\n",
      "  \u001b[31m   \u001b[0m     cmd_obj.run()\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/command/build_ext.py\", line 84, in run\n",
      "  \u001b[31m   \u001b[0m     _build_ext.run(self)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/Cython/Distutils/old_build_ext.py\", line 186, in run\n",
      "  \u001b[31m   \u001b[0m     _build_ext.build_ext.run(self)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/_distutils/command/build_ext.py\", line 346, in run\n",
      "  \u001b[31m   \u001b[0m     self.build_extensions()\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/torch/utils/cpp_extension.py\", line 499, in build_extensions\n",
      "  \u001b[31m   \u001b[0m     _check_cuda_version(compiler_name, compiler_version)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/torch/utils/cpp_extension.py\", line 387, in _check_cuda_version\n",
      "  \u001b[31m   \u001b[0m     raise RuntimeError(CUDA_MISMATCH_MESSAGE.format(cuda_str_version, torch.version.cuda))\n",
      "  \u001b[31m   \u001b[0m RuntimeError:\n",
      "  \u001b[31m   \u001b[0m The detected CUDA version (10.1) mismatches the version that was used to compile\n",
      "  \u001b[31m   \u001b[0m PyTorch (11.8). Please make sure to use the same CUDA versions.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1mlegacy-install-failure\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Encountered error while trying to install package.\n",
      "\u001b[31m╰─>\u001b[0m auto-gptq\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for output from the failure.\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install einops auto-gptq\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf16e1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, pipeline, logging\n",
    "from auto_gptq import AutoGPTQForCausalLM, BaseQuantizeConfig\n",
    "import argparse\n",
    "\n",
    "model_name_or_path = \"TheBloke/Pygmalion-13B-SuperHOT-8K-GPTQ\"\n",
    "model_basename = \"pygmalion-13b-superhot-8k-GPTQ-4bit-128g.no-act.order\"\n",
    "\n",
    "use_triton = False\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, use_fast=True)\n",
    "\n",
    "model = AutoGPTQForCausalLM.from_quantized(model_name_or_path,\n",
    "        model_basename=model_basename,\n",
    "        use_safetensors=True,\n",
    "        trust_remote_code=True,\n",
    "        device_map='auto',\n",
    "        use_triton=use_triton,\n",
    "        quantize_config=None)\n",
    "\n",
    "model.seqlen = 8192\n",
    "\n",
    "# Note: check the prompt template is correct for this model.\n",
    "prompt = \"Tell me about AI\"\n",
    "prompt_template=f'''USER: {prompt}\n",
    "ASSISTANT:'''\n",
    "\n",
    "print(\"\\n\\n*** Generate:\")\n",
    "\n",
    "input_ids = tokenizer(prompt_template, return_tensors='pt').input_ids.cuda()\n",
    "output = model.generate(inputs=input_ids, temperature=0.7, max_new_tokens=512)\n",
    "print(tokenizer.decode(output[0]))\n",
    "\n",
    "# Inference can also be done using transformers' pipeline\n",
    "\n",
    "# Prevent printing spurious transformers error when using pipeline with AutoGPTQ\n",
    "logging.set_verbosity(logging.CRITICAL)\n",
    "\n",
    "print(\"*** Pipeline:\")\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=512,\n",
    "    temperature=0.7,\n",
    "    top_p=0.95,\n",
    "    repetition_penalty=1.15\n",
    ")\n",
    "\n",
    "print(pipe(prompt_template)[0]['generated_text'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
