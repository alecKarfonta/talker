{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc760e69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#notification_trusted {\n",
       "    display: none;\n",
       "}\n",
       "\n",
       "\n",
       ".CodeMirror-sizer {\n",
       "    border-right-color: transparent;\n",
       "    margin-bottom: 0px !important;\n",
       "}\n",
       "\n",
       "div.output_prompt {\n",
       "    color: #ae81ff;\n",
       "    display: none !important;\n",
       "    \n",
       "}\n",
       "\n",
       "div.output_area {\n",
       "    width: 90%\n",
       "}\n",
       "\n",
       ".rendered_html table {\n",
       "    font-size: 14px;\n",
       "}\n",
       "\n",
       ".toc-item-highlight-select {\n",
       "    background-color: rgb(29 0 181) !important;\n",
       "}\n",
       "\n",
       ".toc-item-highlight-execute {\n",
       "    background-color: rgb(7 91 23) !important;\n",
       "}\n",
       "\n",
       "#toc li > span:hover {\n",
       "    background-color: rgb(0 104 186) !important;\n",
       "}\n",
       "\n",
       "\n",
       ".prompt {\n",
       "    display: none;\n",
       "}\n",
       "\n",
       "\n",
       "#toc-wrapper {\n",
       "    background-color: rgb(24, 26, 27);\n",
       "    margin-top: 1.4em;\n",
       "}\n",
       "\n",
       "/* Replace */\n",
       "\n",
       "img {\n",
       "    vertical-align: middle;\n",
       "    text-align: center;\n",
       "    float: left;\n",
       "    position: relative;\n",
       "    margin-left: auto;\n",
       "    margin-right: auto;\n",
       "    display: inherit;\n",
       "}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Style overrides\n",
    "from IPython.core.display import HTML\n",
    "css = open(\"../QA/overrides.css\", \"r\").readlines()\n",
    "css = \"\".join(css)\n",
    "css = f\"<style>{css}</style>\"\n",
    "HTML(css)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfb1e356",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ls /opt/conda/lib/libcud*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ff342c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/opt/conda/lib/libcudart.so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7abaa46c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__init__.py\t\t\t       libbitsandbytes_cuda115.so\r\n",
      "__main__.py\t\t\t       libbitsandbytes_cuda115_nocublaslt.so\r\n",
      "__pycache__\t\t\t       libbitsandbytes_cuda116.so\r\n",
      "autograd\t\t\t       libbitsandbytes_cuda116_nocublaslt.so\r\n",
      "cextension.py\t\t\t       libbitsandbytes_cuda117.so\r\n",
      "cuda_setup\t\t\t       libbitsandbytes_cuda117_nocublaslt.so\r\n",
      "functional.py\t\t\t       libbitsandbytes_cuda118.so\r\n",
      "libbitsandbytes_cpu.so\t\t       libbitsandbytes_cuda118_nocublaslt.so\r\n",
      "libbitsandbytes_cuda110.so\t       libbitsandbytes_cuda120.so\r\n",
      "libbitsandbytes_cuda110_nocublaslt.so  libbitsandbytes_cuda120_nocublaslt.so\r\n",
      "libbitsandbytes_cuda111.so\t       libbitsandbytes_cuda121.so\r\n",
      "libbitsandbytes_cuda111_nocublaslt.so  libbitsandbytes_cuda121_nocublaslt.so\r\n",
      "libbitsandbytes_cuda112.so\t       nn\r\n",
      "libbitsandbytes_cuda112_nocublaslt.so  optim\r\n",
      "libbitsandbytes_cuda113.so\t       research\r\n",
      "libbitsandbytes_cuda113_nocublaslt.so  triton\r\n",
      "libbitsandbytes_cuda114.so\t       utils.py\r\n",
      "libbitsandbytes_cuda114_nocublaslt.so\r\n"
     ]
    }
   ],
   "source": [
    "!ls /opt/conda/lib/python3.10/site-packages/bitsandbytes/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4059e179",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp /opt/conda/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda118.so /opt/conda/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cpu.so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a93ef07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a06ddae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto reload imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a16cc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -r requirements_1.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49e13027",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2d10b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['LD_LIBRARY_PATH'] = '/opt/conda/lib/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c0ac375",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip uninstall -y torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8650f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip uninstall -y torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85a0dd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130cb7cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "55bf6fee",
   "metadata": {},
   "source": [
    "Version Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b374c6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade google-api-python-client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8d8b209",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import IPython\n",
    "import torch\n",
    "import torchaudio\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c1b995b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.__version__ = '2.0.1+cu118'\n"
     ]
    }
   ],
   "source": [
    "print (f\"{torch.__version__ = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36798bc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.2+cu118'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchaudio.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c30734e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformers.__version__ = '4.31.0.dev0'\n"
     ]
    }
   ],
   "source": [
    "print (f\"{transformers.__version__ = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d284a77d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.cuda.is_available() = True\n"
     ]
    }
   ],
   "source": [
    "print (f\"{torch.cuda.is_available() = }\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "54a580e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.version.cuda = '11.8'\n"
     ]
    }
   ],
   "source": [
    "print (f\"{torch.version.cuda = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d5f41b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.cuda.get_device_name(0) = 'NVIDIA GeForce RTX 3090 Ti'\n"
     ]
    }
   ],
   "source": [
    "print (f\"{torch.cuda.get_device_name(0) = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "17877f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2bb14b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "75b34ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install soundfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "89ede365",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dfc07a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install evaluate jiwer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d82f53f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pydub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b6f909",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "22be18cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from copy import copy\n",
    "from typing import List\n",
    "import IPython\n",
    "import transformers\n",
    "from datetime import datetime\n",
    "from numpy.random import random\n",
    "from color import Color\n",
    "\n",
    "#import torchaudio\n",
    "#import IPython.display as ipd\n",
    "\n",
    "from sentiment import Sentiment, SentimentScore\n",
    "from conversation import Conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f80fa0d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:numexpr.utils:Note: NumExpr detected 32 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "INFO:numexpr.utils:NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "bin /opt/conda/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda118.so\n",
      "CUDA SETUP: CUDA runtime path found: /opt/conda/lib/libcudart.so\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.6\n",
      "CUDA SETUP: Detected CUDA version 118\n",
      "CUDA SETUP: Loading binary /opt/conda/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda118.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:torch.distributed.nn.jit.instantiator:Created a temporary directory at /tmp/tmp_4rilyx7\n",
      "INFO:torch.distributed.nn.jit.instantiator:Writing /tmp/tmp_4rilyx7/_remote_module_non_scriptable.py\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import soundfile as sf\n",
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "from datasets import load_dataset\n",
    "from datasets import Audio\n",
    "\n",
    "from transformers import pipeline\n",
    "from transformers import AutoFeatureExtractor\n",
    "from transformers import Speech2TextProcessor\n",
    "from transformers import Speech2Text2Processor\n",
    "from transformers import SpeechEncoderDecoderModel\n",
    "from transformers import Speech2TextForConditionalGeneration\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3d0a7c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"facebook/s2t-small-librispeech-asr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3a6aa705",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Speech2TextForConditionalGeneration were not initialized from the model checkpoint at facebook/s2t-small-librispeech-asr and are newly initialized: ['model.decoder.embed_positions.weights', 'model.encoder.embed_positions.weights']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = Speech2TextForConditionalGeneration.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "63bc9c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = Speech2TextProcessor.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4419322b",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ec2e73c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"hf-internal-testing/librispeech_asr_demo\", \"clean\", split=\"validation\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "095764cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['file', 'audio', 'text', 'speaker_id', 'chapter_id', 'id'],\n",
       "    num_rows: 73\n",
       "})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ab1057b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file = ds[0][\"file\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2772c505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/root/.cache/huggingface/datasets/downloads/extracted/dfbece23564f422bc5794f3090902cd16d52d86767b746125ebc2ff3ea5f89ef/dev_clean/1272/128104/1272-128104-0000.flac'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0121bc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import PurePath\n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769a7d96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "47994800",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IPython.display.display(IPython.display.Audio(\"../output.wav\", rate=22050, autoplay=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4d7495",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e27c54c4",
   "metadata": {},
   "source": [
    "# Init model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "68c2ff81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Speech2TextForConditionalGeneration were not initialized from the model checkpoint at facebook/s2t-small-librispeech-asr and are newly initialized: ['model.decoder.embed_positions.weights', 'model.encoder.embed_positions.weights']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = Speech2TextForConditionalGeneration.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "89c6368d",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = Speech2TextProcessor.from_pretrained(\"facebook/s2t-small-librispeech-asr\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7c3b57ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inputs = processor(ds[0][\"audio\"][\"array\"], sampling_rate=ds[0][\"audio\"][\"sampling_rate\"], return_tensors=\"pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c154546a",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_ids = model.generate(inputs[\"input_features\"], attention_mask=inputs[\"attention_mask\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4abd7445",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcription = processor.batch_decode(generated_ids, skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d5c4ee08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mister quilter is the apostle of the middle classes and we are glad to welcome his gospel'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcription[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "13037031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mister quilter is the apostle of the middle classes and we are glad to welcome his gospel'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[0][\"text\"].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af8cb6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9139e2c4",
   "metadata": {},
   "source": [
    "# Capture Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8396880c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install torchaudio ipywebrtc notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6f9cc9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywebrtc import AudioRecorder, CameraStream\n",
    "import torchaudio\n",
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "856d2d8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "746e326aaea745b7b035342bddb98b7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "AudioRecorder(audio=Audio(value=b'', format='webm'), stream=CameraStream(constraints={'audio': True, 'video': …"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "camera = CameraStream(constraints={'audio': True,'video':False})\n",
    "recorder = AudioRecorder(stream=camera)\n",
    "recorder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a889b71d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffmpeg: /opt/conda/lib/libtinfo.so.6: no version information available (required by /usr/lib/x86_64-linux-gnu/libcaca.so.0)\r\n",
      "ffmpeg: /opt/conda/lib/libncursesw.so.6: no version information available (required by /usr/lib/x86_64-linux-gnu/libcaca.so.0)\r\n",
      "ffmpeg: /opt/conda/lib/libncursesw.so.6: no version information available (required by /usr/lib/x86_64-linux-gnu/libcaca.so.0)\r\n",
      "ffmpeg: symbol lookup error: /usr/lib/x86_64-linux-gnu/libgobject-2.0.so.0: undefined symbol: ffi_type_uint32, version LIBFFI_BASE_7.0\r\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to load audio from file.wav",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(recorder\u001b[38;5;241m.\u001b[39maudio\u001b[38;5;241m.\u001b[39mvalue)\n\u001b[1;32m      3\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mffmpeg -i recording.webm -ac 1 -f wav file.wav -y -hide_banner -loglevel panic\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m sig, sr \u001b[38;5;241m=\u001b[39m \u001b[43mtorchaudio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfile.wav\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(sig\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      6\u001b[0m Audio(data\u001b[38;5;241m=\u001b[39msig, rate\u001b[38;5;241m=\u001b[39msr)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchaudio/backend/sox_io_backend.py:256\u001b[0m, in \u001b[0;36mload\u001b[0;34m(filepath, frame_offset, num_frames, normalize, channels_first, format)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\n\u001b[0;32m--> 256\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_fallback_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannels_first\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchaudio/backend/sox_io_backend.py:30\u001b[0m, in \u001b[0;36m_fail_load\u001b[0;34m(filepath, frame_offset, num_frames, normalize, channels_first, format)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_fail_load\u001b[39m(\n\u001b[1;32m     23\u001b[0m     filepath: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m     24\u001b[0m     frame_offset: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28mformat\u001b[39m: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     29\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor, \u001b[38;5;28mint\u001b[39m]:\n\u001b[0;32m---> 30\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to load audio from \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(filepath))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to load audio from file.wav"
     ]
    }
   ],
   "source": [
    "with open('recording.webm', 'wb') as f:\n",
    "    f.write(recorder.audio.value)\n",
    "!ffmpeg -i recording.webm -ac 1 -f wav file.wav -y -hide_banner -loglevel panic\n",
    "sig, sr = torchaudio.load(\"file.wav\")\n",
    "print(sig.shape)\n",
    "Audio(data=sig, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "eb3ab432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alec_human.p\t\t   __pycache__\t    jupyter_notebook_config.py\r\n",
      "BNB\t\t\t   api\t\t    models\r\n",
      "Billy-Alec_chat_history.p  color.py\t    notebooks\r\n",
      "DatabaseFactory.py\t   comment.py\t    pygmalion_2.ipynb\r\n",
      "Dockerfile_api.sh\t   controllers\t    recording.webm\r\n",
      "Dockerfile_db.sh\t   conversation.py  requirements.txt\r\n",
      "Dockerfile_pytorch_2.sh    custom\t    robot.py\r\n",
      "README.md\t\t   db\t\t    run.sh\r\n",
      "Speech-to-class.ipynb\t   fast_api.py\t    sentiment.py\r\n",
      "Speech-to-text-mid.ipynb   human.py\t    tmpdir_tts\r\n",
      "Speech-to-text-min.ipynb   info.py\t    tmpdir_vocoder\r\n",
      "Untitled.ipynb\t\t   info_cache.p     utils_qa.py\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0502e7bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff6de3346c424d129d153a6e05053a55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.94k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffc7d94ceaaf47ba92def877b7cf8cdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/290M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdec31e5f94141ae991768aacfe3c668",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/1.50k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5b3a1d1d661422bafc742d58ff62496",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/805 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2323d79d957a4a15ab75455649798ed6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e1382028ea441a99f6f3a98a37a7b10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.41M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3e9016d30de48bfbbbece15200a36bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "741c6101f7af4ce8b8e953b0a92d6902",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)main/normalizer.json:   0%|          | 0.00/52.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de3c9f54e0094713be75a5371b70cf51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)in/added_tokens.json:   0%|          | 0.00/34.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85a3b3b398304533890123fd5d2c1c61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/1.83k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1f4ce555ae443cfbe275803dab39f05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)rocessor_config.json:   0%|          | 0.00/185k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg: /opt/conda/lib/libtinfo.so.6: no version information available (required by /lib/x86_64-linux-gnu/libcaca.so.0)\n",
      "ffmpeg: /opt/conda/lib/libncursesw.so.6: no version information available (required by /lib/x86_64-linux-gnu/libcaca.so.0)\n",
      "ffmpeg: /opt/conda/lib/libncursesw.so.6: no version information available (required by /lib/x86_64-linux-gnu/libcaca.so.0)\n",
      "ffmpeg: symbol lookup error: /lib/x86_64-linux-gnu/libgobject-2.0.so.0: undefined symbol: ffi_type_uint32, version LIBFFI_BASE_7.0\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import torch\n",
    "from transformers.pipelines.audio_utils import ffmpeg_microphone_live\n",
    "import sys\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "transcriber = pipeline(\n",
    "    \"automatic-speech-recognition\", model=\"openai/whisper-base.en\", device=device\n",
    ")\n",
    "\n",
    "\n",
    "def transcribe(chunk_length_s=15.0, stream_chunk_s=1.0):\n",
    "    sampling_rate = transcriber.feature_extractor.sampling_rate\n",
    "\n",
    "    mic = ffmpeg_microphone_live(\n",
    "        sampling_rate=sampling_rate,\n",
    "        chunk_length_s=chunk_length_s,\n",
    "        stream_chunk_s=stream_chunk_s,\n",
    "    )\n",
    "\n",
    "    print(\"Ready\")\n",
    "    for item in transcriber(mic, generate_kwargs={\"max_new_tokens\": 128}):\n",
    "        sys.stdout.write(\"\\033[K\")\n",
    "        print(item[\"text\"], end=\"\\r\")\n",
    "        if not item[\"partial\"][0]:\n",
    "            break\n",
    "\n",
    "transcribe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a75030a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7a933c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36256935",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0447cf29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77435eca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa46fa06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6a3720",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
