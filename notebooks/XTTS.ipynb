{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f16f286",
   "metadata": {},
   "source": [
    "# Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3b41ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install espeakng\n",
    "#!pip install speechbrain\n",
    "#!pip install -r requirements_1.txt\n",
    "#import nltk\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('averaged_perceptron_tagger')\n",
    "#!pip install numpy==1.24 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ffcc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install python-Levenshtein\n",
    "#!pip install num2words\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e461e1",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125f7e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c304736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto reload imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69b5972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add user class to path\n",
    "import sys\n",
    "sys.path.append('../reader')\n",
    "sys.path.append('../shared')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5311b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7deb7b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import copy\n",
    "import os\n",
    "from num2words import num2words\n",
    "\n",
    "from Levenshtein import distance\n",
    "import os\n",
    "import librosa   \n",
    "import soundfile as sf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcb8681",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "from TTS.api import TTS\n",
    "from color import Color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f499c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def expose(prefix:str=\"\"):\n",
    "    import torch\n",
    "    print (f\"{prefix}{torch.__version__ = }\")\n",
    "    import transformers\n",
    "    print (f\"{prefix}{transformers.__version__ = }\")\n",
    "    import nltk\n",
    "    print (f\"{prefix}{nltk.__version__ = }\")\n",
    "    import speechbrain\n",
    "    print (f\"{prefix}{speechbrain.__version__ = }\")\n",
    "    import TTS\n",
    "    print (f\"{prefix}{TTS.__version__ = }\")\n",
    "    import datasets\n",
    "    print (f\"{prefix}{datasets.__version__ = }\")\n",
    "expose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e13027",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d98e891d",
   "metadata": {},
   "source": [
    "# Define inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbdb4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \"\"\"\"\"\"\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca94eeb5",
   "metadata": {},
   "source": [
    "# SST Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a15bbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2763bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# load model and processor\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-large-v2\")\n",
    "stt_model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-large-v2\")\n",
    "stt_model.config.forced_decoder_ids = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0fab7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stt_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b0c386",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe(model, wav, samplerate=24000):\n",
    "    input_features = processor(wav, sampling_rate=samplerate, return_tensors=\"pt\").input_features \n",
    "    input_features = input_features.to(\"cuda\")\n",
    "    predicted_ids = model.generate(input_features)\n",
    "    transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)\n",
    "    return transcription"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1a34b0",
   "metadata": {},
   "source": [
    "# XTTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a973e4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39abb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install deepspeed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4ef981",
   "metadata": {},
   "outputs": [],
   "source": [
    "from TTS.tts.models.xtts import Xtts\n",
    "from TTS.utils.manage import ModelManager\n",
    "from TTS.tts.configs.xtts_config import XttsConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f66cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ModelManager().list_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cb2af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"tts_models/multilingual/multi-dataset/xtts_v1.1\"\n",
    "ModelManager().download_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ae605c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelManager().download_model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6939d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdf67c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91190fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ls /root/.local/share/tts/tts_models--multilingual--multi-dataset--xtts_v1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cfb830",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/root/.local/share/tts/tts_models--multilingual--multi-dataset--xtts_v1.1/model.pth\"\n",
    "model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899433d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = \"/root/.local/share/tts/tts_models--multilingual--multi-dataset--xtts_v1.1/config.json\"\n",
    "vocab_path = \"/root/.local/share/tts/tts_models--multilingual--multi-dataset--xtts_v1.1/vocab.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91033d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = XttsConfig()\n",
    "config.load_json(config_path)\n",
    "\n",
    "config.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2224fbc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969c2d20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c80daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Xtts.init_from_config(config)\n",
    "model.load_checkpoint(\n",
    "    config,\n",
    "    checkpoint_path=model_path,\n",
    "    vocab_path=vocab_path,\n",
    "    eval=True,\n",
    "    use_deepspeed=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5355593",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2341a26c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa1e329",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "outputs = model.synthesize(\n",
    "    texts[1],\n",
    "    config,\n",
    "    speaker_wav=\"../data/trey.wav\",\n",
    "    gpt_cond_len=3,\n",
    "    language=\"en\",\n",
    "    top_k=3,\n",
    "    top_p=5,\n",
    "    decoder_iterations=10,\n",
    "    #repetition_penalty=.75\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b015c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c5d237",
   "metadata": {},
   "outputs": [],
   "source": [
    "wav = outputs[\"wav\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2661ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#text = \"one nine five five zero\"\n",
    "#text = \"zero nine zero twenty seven\"\n",
    "text = \"Alec you get a big bonus!\"\n",
    "synth_params = {\n",
    "    \"gpt_cond_len\" : 8,\n",
    "    \"top_k\" : 50, # Default 50\n",
    "    \"top_p\" : 0.85, # Default 0.85\n",
    "    \"decoder_iterations\" : 10, # Default 30\n",
    "    \"temperature\" : 0.1, # Default 0.85\n",
    "    \"length_penalty\" : 1.0, # Default 1.0\n",
    "    \"repetition_penalty\" : 2.0, # Default 2.0\n",
    "    \"cond_free_k\" : 2.0, # Default 2.0\n",
    "    \"diffusion_temperature\" : 1.0, # Default 1.0    \n",
    "}\n",
    "outputs = model.synthesize(\n",
    "    text,\n",
    "    config,\n",
    "    speaker_wav=\"../data/trey.wav\",\n",
    "    language=\"en\",\n",
    "    **synth_params\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021afeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e464cfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbe1fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.display(IPython.display.Audio(outputs[\"wav\"], rate=24000, autoplay=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e442868",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd976e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95e2a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to local file\n",
    "sf.write(\"cache/cache_24.wav\", outputs[\"wav\"], 24000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479d4de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(f\"ffmpeg -y -i cache/cache_24.wav -ar 16000 cache/cache_16.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757602d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_output(wav):\n",
    "    sf.write(\"cache/cache_24.wav\", wav, 24000)\n",
    "    os.system(f\"ffmpeg -y -hide_banner -loglevel error -i cache/cache_24.wav -ar 16000 cache/cache_16.wav\")\n",
    "    y, fs = sf.read(\"cache/cache_16.wav\")\n",
    "    return transcribe(stt_model, y, samplerate=16000)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184d08bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc91c5ae",
   "metadata": {},
   "source": [
    "## Param tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34783c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lthresh_good = 10\n",
    "lthresh_mid = 20\n",
    "lthresh_bad = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad55a4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lcolor(ldist):\n",
    "    lcolor = Color.F_Green\n",
    "    if ldist > lthresh_mid:\n",
    "        lcolor = Color.F_Yellow\n",
    "    if ldist > lthresh_bad:\n",
    "        lcolor = Color.F_Red\n",
    "    return lcolor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ac13c3",
   "metadata": {},
   "source": [
    "### Gpt conds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eec2fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_conds = [1,3,5,7,11,15,21,32,64,128,256,512,1024,2048,4096]\n",
    "for gpt_cond in gpt_conds:\n",
    "    text = \"\"\n",
    "    \n",
    "    test_config = copy(synth_params)\n",
    "    test_config[\"gpt_cond_len\"] = gpt_cond\n",
    "    \n",
    "    outputs = model.synthesize(\n",
    "        text,\n",
    "        config,\n",
    "        speaker_wav=\"../data/trey.wav\",\n",
    "        language=\"en\",\n",
    "        **test_config\n",
    "        #repetition_penalty=.75\n",
    "    )\n",
    "    transcription = transcribe_output(outputs[\"wav\"])\n",
    "    if isinstance(transcription, list) and len(transcription) > 1:\n",
    "        print (\"more than one output received\")\n",
    "    else:\n",
    "        transcription = transcription[0]\n",
    "    \n",
    "    transcription = transcription.lower()\n",
    "    text = text.lower()\n",
    "    \n",
    "    ldist = distance(transcription, text)\n",
    "    lcolor = get_lcolor(ldist)\n",
    "    print (f\"{gpt_cond = }\")\n",
    "    print (f\"Original Text: {text}\")\n",
    "    print (f\"Transcription: {transcription}\")\n",
    "    print (f\"Levenstein: {lcolor}{ldist}{Color.F_White}\")\n",
    "    \n",
    "    IPython.display.display(IPython.display.Audio(outputs[\"wav\"], rate=24050, autoplay=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efe6010",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5293b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "num2words(27023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6b1d13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec84af1c",
   "metadata": {},
   "source": [
    "### Top k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9148c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_ks = [1,3,5,7,11,15, 32,64,128,512]\n",
    "for top_k in top_ks:\n",
    "\n",
    "    text = \"\"\n",
    "    \n",
    "    test_config = copy(synth_params)\n",
    "    test_config[\"top_k\"] = top_k\n",
    "    \n",
    "    \n",
    "    outputs = model.synthesize(\n",
    "        text,\n",
    "        config,\n",
    "        speaker_wav=\"../data/trey.wav\",\n",
    "        language=\"en\",\n",
    "        **test_config\n",
    "    )\n",
    "    \n",
    "    transcription = transcribe_output(outputs[\"wav\"])\n",
    "    if isinstance(transcription, list) and len(transcription) > 1:\n",
    "        print (\"more than one output received\")\n",
    "    else:\n",
    "        transcription = transcription[0]\n",
    "    \n",
    "    transcription = transcription.lower()\n",
    "    text = text.lower()\n",
    "    \n",
    "    ldist = distance(transcription, text)\n",
    "    lcolor = get_lcolor(ldist)\n",
    "    print (f\"{top_k = }\")\n",
    "    print (f\"Original Text: {text}\")\n",
    "    print (f\"Transcription: {transcription}\")\n",
    "    print (f\"Levenstein: {lcolor}{ldist}{Color.F_White}\")\n",
    "    \n",
    "    IPython.display.display(IPython.display.Audio(outputs[\"wav\"], rate=24050, autoplay=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a7e874",
   "metadata": {},
   "source": [
    "### Top P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53015488",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_p = [0.001, 0.01, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 0.99]\n",
    "for top_p in top_p:\n",
    "\n",
    "    text = \"\"\n",
    "    \n",
    "    \n",
    "    test_config = copy(synth_params)\n",
    "    test_config[\"top_p\"] = top_p\n",
    "    \n",
    "    outputs = model.synthesize(\n",
    "        text,\n",
    "        config,\n",
    "        speaker_wav=\"../data/trey.wav\",\n",
    "        language=\"en\",\n",
    "        **test_config\n",
    "    )\n",
    "    \n",
    "    transcription = transcribe_output(outputs[\"wav\"])\n",
    "    if isinstance(transcription, list) and len(transcription) > 1:\n",
    "        print (\"more than one output received\")\n",
    "    else:\n",
    "        transcription = transcription[0]\n",
    "    \n",
    "    transcription = transcription.lower()\n",
    "    text = text.lower()\n",
    "    \n",
    "    ldist = distance(transcription, text)\n",
    "    lcolor = get_lcolor(ldist)\n",
    "    print (f\"{top_p = }\")\n",
    "    print (f\"Original Text: {text}\")\n",
    "    print (f\"Transcription: {transcription}\")\n",
    "    print (f\"Levenstein: {lcolor}{ldist}{Color.F_White}\")\n",
    "    \n",
    "    IPython.display.display(IPython.display.Audio(outputs[\"wav\"], rate=24050, autoplay=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ac4237",
   "metadata": {},
   "source": [
    "### Decoder Iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e71f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_iters = [1,3,5,7,11,15,64,128,512]\n",
    "for decoder_iter in decoder_iters:\n",
    "\n",
    "    text = \"\"\n",
    "    \n",
    "    test_config = copy(synth_params)\n",
    "    test_config[\"decoder_iterations\"] = decoder_iter\n",
    "    \n",
    "    outputs = model.synthesize(\n",
    "        text,\n",
    "        config,\n",
    "        speaker_wav=\"../data/trey.wav\",\n",
    "        language=\"en\",\n",
    "        **test_config\n",
    "    )\n",
    "    \n",
    "    transcription = transcribe_output(outputs[\"wav\"])\n",
    "    if isinstance(transcription, list) and len(transcription) > 1:\n",
    "        print (\"more than one output received\")\n",
    "    else:\n",
    "        transcription = transcription[0]\n",
    "    \n",
    "    transcription = transcription.lower()\n",
    "    text = text.lower()\n",
    "    \n",
    "    ldist = distance(transcription, text)\n",
    "    lcolor = get_lcolor(ldist)\n",
    "    print (f\"{decoder_iter = }\")\n",
    "    print (f\"Original Text: {text}\")\n",
    "    print (f\"Transcription: {transcription}\")\n",
    "    print (f\"Levenstein: {lcolor}{ldist}{Color.F_White}\")\n",
    "    \n",
    "    IPython.display.display(IPython.display.Audio(outputs[\"wav\"], rate=24050, autoplay=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4364553",
   "metadata": {},
   "source": [
    "### Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a868c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "temps = [0.001, 0.005, 0.01, 0.05, 0.1, 0.15, 0.2, 0.25, 0.30, 0.35, 0.40, 0.45, 0.5]\n",
    "for temp in temps:\n",
    "\n",
    "    text = \"\"\n",
    "    \n",
    "    test_config = copy(synth_params)\n",
    "    test_config[\"temperature\"] = temp\n",
    "    \n",
    "    outputs = model.synthesize(\n",
    "        text,\n",
    "        config,\n",
    "        speaker_wav=\"../data/trey.wav\",\n",
    "        language=\"en\",\n",
    "        **test_config\n",
    "    )\n",
    "    \n",
    "    transcription = transcribe_output(outputs[\"wav\"])\n",
    "    if isinstance(transcription, list) and len(transcription) > 1:\n",
    "        print (\"more than one output received\")\n",
    "    else:\n",
    "        transcription = transcription[0]\n",
    "    \n",
    "    transcription = transcription.lower()\n",
    "    text = text.lower()\n",
    "    \n",
    "    ldist = distance(transcription, text)\n",
    "    lcolor = get_lcolor(ldist)\n",
    "    print (f\"{temp = }\")\n",
    "    print (f\"Original Text: {text}\")\n",
    "    print (f\"Transcription: {transcription}\")\n",
    "    print (f\"Levenstein: {lcolor}{ldist}{Color.F_White}\")\n",
    "    \n",
    "    IPython.display.display(IPython.display.Audio(outputs[\"wav\"], rate=24050, autoplay=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ae92de",
   "metadata": {},
   "source": [
    "### Repition penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93658c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "reps = [0.001, 0.01, 0.1, 0.2, 0.5, 0.75, 1.0, 1.25, 1.5, 1.75, 1.9, 1.99, 2.5, 3.0, 4.0, 5.0]\n",
    "for rep in reps:\n",
    "\n",
    "    text = \"\"\n",
    "    \n",
    "    test_config = copy(synth_params)\n",
    "    test_config[\"repetition_penalty\"] = rep\n",
    "    \n",
    "    outputs = model.synthesize(\n",
    "        text,\n",
    "        config,\n",
    "        speaker_wav=\"../data/trey.wav\",\n",
    "        language=\"en\",\n",
    "        **test_config\n",
    "    )\n",
    "    \n",
    "    transcription = transcribe_output(outputs[\"wav\"])\n",
    "    if isinstance(transcription, list) and len(transcription) > 1:\n",
    "        print (\"more than one output received\")\n",
    "    else:\n",
    "        transcription = transcription[0]\n",
    "    \n",
    "    transcription = transcription.lower()\n",
    "    text = text.lower()\n",
    "    \n",
    "    ldist = distance(transcription, text)\n",
    "    lcolor = get_lcolor(ldist)\n",
    "    print (f\"{rep = }\")\n",
    "    print (f\"Original Text: {text}\")\n",
    "    print (f\"Transcription: {transcription}\")\n",
    "    print (f\"Levenstein: {lcolor}{ldist}{Color.F_White}\")\n",
    "    \n",
    "    IPython.display.display(IPython.display.Audio(outputs[\"wav\"], rate=24050, autoplay=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85acedcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "synth_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2647e49e",
   "metadata": {},
   "source": [
    "### Diffusion temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc99cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "temps = [0.001, 0.005, 0.01, 0.05, 0.1, 0.15, 0.2, 0.25, 0.35, 0.5, 0.6, 0.75, 0.85, 0.95, 0.99]\n",
    "for temp in temps:\n",
    "\n",
    "    text = \"\"\n",
    "    \n",
    "    test_config = copy(synth_params)\n",
    "    test_config[\"diffusion_temperature\"] = temp\n",
    "    \n",
    "    outputs = model.synthesize(\n",
    "        text,\n",
    "        config,\n",
    "        speaker_wav=\"../data/trey.wav\",\n",
    "        language=\"en\",\n",
    "        **test_config\n",
    "    )\n",
    "    \n",
    "    transcription = transcribe_output(outputs[\"wav\"])\n",
    "    if isinstance(transcription, list) and len(transcription) > 1:\n",
    "        print (\"more than one output received\")\n",
    "    else:\n",
    "        transcription = transcription[0]\n",
    "    \n",
    "    transcription = transcription.lower()\n",
    "    text = text.lower()\n",
    "    \n",
    "    ldist = distance(transcription, text)\n",
    "    lcolor = get_lcolor(ldist)\n",
    "    print (f\"{temp = }\")\n",
    "    print (f\"Original Text: {text}\")\n",
    "    print (f\"Transcription: {transcription}\")\n",
    "    print (f\"Levenstein: {lcolor}{ldist}{Color.F_White}\")\n",
    "    \n",
    "    IPython.display.display(IPython.display.Audio(outputs[\"wav\"], rate=24050, autoplay=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e534a75b",
   "metadata": {},
   "source": [
    "### Cond free k\n",
    "cond_free_k default 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af72bfa1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ks = [0.1, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0]\n",
    "for k in ks:\n",
    "\n",
    "    text = \"\"\n",
    "    \n",
    "    test_config = copy(synth_params)\n",
    "    test_config[\"cond_free_k\"] = k\n",
    "    \n",
    "    outputs = model.synthesize(\n",
    "        text,\n",
    "        config,\n",
    "        speaker_wav=\"../data/trey.wav\",\n",
    "        language=\"en\",\n",
    "        **test_config\n",
    "    )\n",
    "    \n",
    "    wav = outputs[\"wav\"]\n",
    "    \n",
    "    sf.write(\"cache/test.wav\", wav, 24000)\n",
    "    sound = AudioSegment.from_file(\"cache/test.wav\", format = \"wav\")\n",
    "    sound = sound.strip_silence(silence_len=250, silence_thresh=-50, padding=100)\n",
    "    wav = np.array(sound.get_array_of_samples())\n",
    "    \n",
    "    transcription = transcribe_output(wav)\n",
    "    if isinstance(transcription, list) and len(transcription) > 1:\n",
    "        print (\"more than one output received\")\n",
    "    else:\n",
    "        transcription = transcription[0]\n",
    "    \n",
    "    transcription = transcription.lower()\n",
    "    text = text.lower()\n",
    "    \n",
    "    ldist = distance(transcription, text)\n",
    "    lcolor = get_lcolor(ldist)\n",
    "    print (f\"{k = }\")\n",
    "    print (f\"Original Text: {text}\")\n",
    "    print (f\"Transcription: {transcription}\")\n",
    "    print (f\"Levenstein: {lcolor}{ldist}{Color.F_White}\")\n",
    "    \n",
    "    \n",
    "    IPython.display.display(IPython.display.Audio(outputs[\"wav\"], rate=24050, autoplay=False))\n",
    "    plt.plot(outputs[\"wav\"])\n",
    "    plt.show()\n",
    "    IPython.display.display(IPython.display.Audio(wav, rate=24050, autoplay=False))\n",
    "    plt.plot(wav)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a53e77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cdf8a50e",
   "metadata": {},
   "source": [
    "# Remove silence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c6eb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_leading_silence(sound, silence_threshold=-50.0, chunk_size=10):\n",
    "    '''\n",
    "    sound is a pydub.AudioSegment\n",
    "    silence_threshold in dB\n",
    "    chunk_size in ms\n",
    "\n",
    "    iterate over chunks until you find the first one with sound\n",
    "    '''\n",
    "    trim_ms = 0 # ms\n",
    "\n",
    "    assert chunk_size > 0 # to avoid infinite loop\n",
    "    while sound[trim_ms:trim_ms+chunk_size].dBFS < silence_threshold and trim_ms < len(sound):\n",
    "        trim_ms += chunk_size\n",
    "\n",
    "    return trim_ms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9c7b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "start_trim = detect_leading_silence(wav)\n",
    "end_trim = detect_leading_silence(wav.reverse())\n",
    "\n",
    "duration = len(sound)    \n",
    "trimmed_sound = sound[start_trim:duration-end_trim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a76c93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2137a3db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af736394",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AudioSegment(wav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fe2d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#plt.style.use([\"seaborn-darkgrid\"])\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 6)\n",
    "plt.rcParams[\"figure.facecolor\"] = \"black\"\n",
    "plt.rcParams[\"axes.facecolor\"] = \"black\"\n",
    "plt.rcParams[\"axes.edgecolor\"] = \"white\"\n",
    "plt.rcParams[\"xtick.color\"] = \"white\"\n",
    "plt.rcParams[\"ytick.color\"] = \"white\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f654b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "wav = outputs[\"wav\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0db3862",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sf.write(\"cache/test.wav\", wav, 24000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdff08eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(wav)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72343453",
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.display(IPython.display.Audio(wav, rate=24000, autoplay=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea02304",
   "metadata": {},
   "outputs": [],
   "source": [
    "sf.write(\"cache/test.wav\", wav, 24000)\n",
    "sound = AudioSegment.from_file(\"cache/test.wav\", format = \"wav\")\n",
    "sound = sound.strip_silence(silence_len=250, silence_thresh=-50, padding=100)\n",
    "wav = np.array(sound.get_array_of_samples())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f18ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(wav)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad1016d",
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.display(IPython.display.Audio(wav, rate=24000, autoplay=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09603545",
   "metadata": {},
   "outputs": [],
   "source": [
    "sound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756d689d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c703851c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c100da1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sound.strip_silence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63a18be",
   "metadata": {},
   "outputs": [],
   "source": [
    "sound.strip_silence(silence_len=1000, silence_thresh=-50, padding=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e0d847",
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.display(IPython.display.Audio(sound.get_array_of_samples(), rate=24000, autoplay=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cfc932",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4e652b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc8da84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafd23f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(audio_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d85084",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_chunks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2421e719",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_chunks[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca6d0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(audio_chunks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259d0862",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_chunks[0].speedup(1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97e0a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_chunks[0]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f186ec1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c661d05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9b1d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(sound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d88a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ce6311",
   "metadata": {},
   "outputs": [],
   "source": [
    "wav.dtype.itemsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3463de5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becdb111",
   "metadata": {},
   "outputs": [],
   "source": [
    "pydub.AudioSegment.from_numpy_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e5075c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b295046",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bb0e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "AudioSegment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5e740c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c1131c",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_segment = pydub.AudioSegment(\n",
    "    wav.tobytes(), \n",
    "    frame_rate=24000,\n",
    "    sample_width=wav.dtype.itemsize, \n",
    "    channels=1\n",
    ")\n",
    "audio_chunks = split_on_silence(audio_segment\n",
    "                            ,min_silence_len = 100\n",
    "                            ,silence_thresh = -45\n",
    "                            ,keep_silence = 50\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4753b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d230b675",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_chunks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32005f26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b271e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e79e96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ae44ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d39ef80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8369d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment, silence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb59c2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "silence = silence.detect_silence(wav, min_silence_len=1000, silence_thresh=-16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e17202",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2973f85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9f82a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ac7c3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2238fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa39047",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pydub.silence import split_on_silence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f829b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42adc43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "aud = AudioSegment(audio.tobytes(),frame_rate = rate,\n",
    "                     sample_width = audio.dtype.itemsize,channels = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39101d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_chunks = split_on_silence(\n",
    "    aud,\n",
    "    min_silence_len = 2000,\n",
    "    silence_thresh = -45,\n",
    "    keep_silence = 500,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a582f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_processed = sum(audio_chunks)\n",
    "audio_processed = np.array(audio_processed.get_array_of_samples())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1320af0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f01fb7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9dcd7b88",
   "metadata": {},
   "source": [
    "## Tuned sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18611c04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e62e92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5df2de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_texts = [\n",
    "    ''\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a97b3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_output(model, text, synth_params):\n",
    "    \n",
    "    outputs = model.synthesize(\n",
    "        text,\n",
    "        config,\n",
    "        speaker_wav=\"../data/trey.wav\",\n",
    "        language=\"en\",\n",
    "        **synth_params\n",
    "\n",
    "    )\n",
    "    \n",
    "    wav = outputs[\"wav\"]\n",
    "    \n",
    "    sf.write(\"cache/test.wav\", wav, 24000)\n",
    "    sound = AudioSegment.from_file(\"cache/test.wav\", format = \"wav\")\n",
    "    sound = sound.strip_silence(silence_len=250, silence_thresh=-50, padding=100)\n",
    "    wav = np.array(sound.get_array_of_samples())\n",
    "    \n",
    "    \n",
    "    transcription = transcribe_output(wav)\n",
    "    if isinstance(transcription, list) and len(transcription) > 1:\n",
    "        print (\"more than one output received\")\n",
    "    else:\n",
    "        transcription = transcription[0]\n",
    "    \n",
    "    transcription = transcription.lower()\n",
    "    text = text.lower()\n",
    "    \n",
    "    ldist = distance(transcription, text)\n",
    "    lcolor = get_lcolor(ldist)\n",
    "    \n",
    "    print(index)\n",
    "    print (f\"Original Text: {text}\")\n",
    "    print (f\"Transcription: {transcription}\")\n",
    "    print (f\"Levenstein: {lcolor}{ldist}{Color.F_White}\")\n",
    "    \n",
    "    return wav, text, transcription, ldist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588e4696",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae75751",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0272adfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "synth_params = {\n",
    "        #\"gpt_cond_len\" : 4096,\n",
    "        \"top_k\" : 64, # Default 50\n",
    "        \"top_p\" : 0.85, # Default 0.85\n",
    "        \"decoder_iterations\" : 10,\n",
    "        \"temperature\" : 0.1, # Default 0.85\n",
    "        \"length_penalty\" : 1.0, # Default 1.0\n",
    "        \"repetition_penalty\" : 1.8, # Default 2.0\n",
    "        \"cond_free_k\" : 2.0, # Default 2.0\n",
    "        \"diffusion_temperature\" : 1.0, # Default 1.0    \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcf3c59",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "index = 0\n",
    "wavs = []\n",
    "sum_ldist = 0\n",
    "for text in temp_texts:\n",
    "    print (\"-\"*100)\n",
    "    #for iteration in range(10): \n",
    "    wav, text, transcription, ldist = get_model_output(model, text, synth_params)\n",
    "\n",
    "    IPython.display.display(IPython.display.Audio(wav, rate=24050, autoplay=False))\n",
    "    \n",
    "    print (\"-\"*100)\n",
    "    wavs.append(outputs[\"wav\"])\n",
    "    index += 1\n",
    "    sum_ldist += ldist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c63b52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b13e3e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f741534a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_ldist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b433fd01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c25bd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d799363",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pydub.silence import split_on_silence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b604959",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "278.247px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
